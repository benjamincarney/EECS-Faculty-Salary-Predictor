{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:101: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1, iter    10] loss: 59.278 eplased time 0.019\n",
      "[epoch 1, iter    20] loss: 53.365 eplased time 0.016\n",
      "[epoch 1, iter    30] loss: 53.615 eplased time 0.017\n",
      "[epoch 1, iter    40] loss: 53.660 eplased time 0.018\n",
      "[epoch 1, iter    50] loss: 54.949 eplased time 0.019\n",
      "[epoch 1, iter    60] loss: 60.054 eplased time 0.021\n",
      "[epoch 1, iter    70] loss: 52.527 eplased time 0.020\n",
      "[epoch 1, iter    80] loss: 51.395 eplased time 0.019\n",
      "[epoch 2, iter    10] loss: 51.987 eplased time 0.020\n",
      "[epoch 2, iter    20] loss: 55.334 eplased time 0.020\n",
      "[epoch 2, iter    30] loss: 54.721 eplased time 0.017\n",
      "[epoch 2, iter    40] loss: 55.771 eplased time 0.023\n",
      "[epoch 2, iter    50] loss: 56.699 eplased time 0.024\n",
      "[epoch 2, iter    60] loss: 55.777 eplased time 0.023\n",
      "[epoch 2, iter    70] loss: 51.875 eplased time 0.020\n",
      "[epoch 2, iter    80] loss: 54.608 eplased time 0.019\n",
      "[epoch 3, iter    10] loss: 53.857 eplased time 0.019\n",
      "[epoch 3, iter    20] loss: 56.749 eplased time 0.019\n",
      "[epoch 3, iter    30] loss: 54.700 eplased time 0.019\n",
      "[epoch 3, iter    40] loss: 50.806 eplased time 0.018\n",
      "[epoch 3, iter    50] loss: 56.326 eplased time 0.017\n",
      "[epoch 3, iter    60] loss: 52.834 eplased time 0.019\n",
      "[epoch 3, iter    70] loss: 57.508 eplased time 0.023\n",
      "[epoch 3, iter    80] loss: 50.071 eplased time 0.020\n",
      "[epoch 4, iter    10] loss: 52.844 eplased time 0.018\n",
      "[epoch 4, iter    20] loss: 56.305 eplased time 0.019\n",
      "[epoch 4, iter    30] loss: 49.526 eplased time 0.019\n",
      "[epoch 4, iter    40] loss: 52.901 eplased time 0.018\n",
      "[epoch 4, iter    50] loss: 56.280 eplased time 0.017\n",
      "[epoch 4, iter    60] loss: 58.383 eplased time 0.016\n",
      "[epoch 4, iter    70] loss: 49.038 eplased time 0.016\n",
      "[epoch 4, iter    80] loss: 53.289 eplased time 0.015\n",
      "[epoch 5, iter    10] loss: 50.548 eplased time 0.016\n",
      "[epoch 5, iter    20] loss: 60.041 eplased time 0.016\n",
      "[epoch 5, iter    30] loss: 53.085 eplased time 0.021\n",
      "[epoch 5, iter    40] loss: 49.478 eplased time 0.020\n",
      "[epoch 5, iter    50] loss: 46.738 eplased time 0.021\n",
      "[epoch 5, iter    60] loss: 57.883 eplased time 0.017\n",
      "[epoch 5, iter    70] loss: 53.769 eplased time 0.016\n",
      "[epoch 5, iter    80] loss: 51.936 eplased time 0.017\n",
      "[epoch 6, iter    10] loss: 48.776 eplased time 0.016\n",
      "[epoch 6, iter    20] loss: 54.023 eplased time 0.016\n",
      "[epoch 6, iter    30] loss: 58.071 eplased time 0.017\n",
      "[epoch 6, iter    40] loss: 46.985 eplased time 0.019\n",
      "[epoch 6, iter    50] loss: 51.397 eplased time 0.019\n",
      "[epoch 6, iter    60] loss: 53.585 eplased time 0.020\n",
      "[epoch 6, iter    70] loss: 58.629 eplased time 0.023\n",
      "[epoch 6, iter    80] loss: 48.095 eplased time 0.023\n",
      "[epoch 7, iter    10] loss: 51.988 eplased time 0.024\n",
      "[epoch 7, iter    20] loss: 53.102 eplased time 0.019\n",
      "[epoch 7, iter    30] loss: 54.192 eplased time 0.020\n",
      "[epoch 7, iter    40] loss: 48.772 eplased time 0.018\n",
      "[epoch 7, iter    50] loss: 51.926 eplased time 0.017\n",
      "[epoch 7, iter    60] loss: 56.659 eplased time 0.016\n",
      "[epoch 7, iter    70] loss: 51.923 eplased time 0.016\n",
      "[epoch 7, iter    80] loss: 49.973 eplased time 0.017\n",
      "[epoch 8, iter    10] loss: 47.239 eplased time 0.019\n",
      "[epoch 8, iter    20] loss: 50.751 eplased time 0.019\n",
      "[epoch 8, iter    30] loss: 48.557 eplased time 0.019\n",
      "[epoch 8, iter    40] loss: 55.667 eplased time 0.017\n",
      "[epoch 8, iter    50] loss: 50.373 eplased time 0.016\n",
      "[epoch 8, iter    60] loss: 55.616 eplased time 0.016\n",
      "[epoch 8, iter    70] loss: 56.154 eplased time 0.016\n",
      "[epoch 8, iter    80] loss: 49.518 eplased time 0.016\n",
      "[epoch 9, iter    10] loss: 48.852 eplased time 0.018\n",
      "[epoch 9, iter    20] loss: 57.629 eplased time 0.016\n",
      "[epoch 9, iter    30] loss: 51.233 eplased time 0.018\n",
      "[epoch 9, iter    40] loss: 48.273 eplased time 0.016\n",
      "[epoch 9, iter    50] loss: 52.154 eplased time 0.017\n",
      "[epoch 9, iter    60] loss: 51.552 eplased time 0.021\n",
      "[epoch 9, iter    70] loss: 46.858 eplased time 0.018\n",
      "[epoch 9, iter    80] loss: 55.123 eplased time 0.017\n",
      "[epoch 10, iter    10] loss: 57.535 eplased time 0.016\n",
      "[epoch 10, iter    20] loss: 48.985 eplased time 0.016\n",
      "[epoch 10, iter    30] loss: 51.436 eplased time 0.016\n",
      "[epoch 10, iter    40] loss: 46.706 eplased time 0.018\n",
      "[epoch 10, iter    50] loss: 51.881 eplased time 0.017\n",
      "[epoch 10, iter    60] loss: 48.523 eplased time 0.016\n",
      "[epoch 10, iter    70] loss: 49.679 eplased time 0.016\n",
      "[epoch 10, iter    80] loss: 54.300 eplased time 0.016\n",
      "[epoch 11, iter    10] loss: 49.902 eplased time 0.018\n",
      "[epoch 11, iter    20] loss: 52.739 eplased time 0.022\n",
      "[epoch 11, iter    30] loss: 55.441 eplased time 0.018\n",
      "[epoch 11, iter    40] loss: 48.430 eplased time 0.020\n",
      "[epoch 11, iter    50] loss: 45.790 eplased time 0.016\n",
      "[epoch 11, iter    60] loss: 52.509 eplased time 0.016\n",
      "[epoch 11, iter    70] loss: 47.633 eplased time 0.018\n",
      "[epoch 11, iter    80] loss: 51.984 eplased time 0.017\n",
      "[epoch 12, iter    10] loss: 50.322 eplased time 0.016\n",
      "[epoch 12, iter    20] loss: 53.535 eplased time 0.017\n",
      "[epoch 12, iter    30] loss: 51.179 eplased time 0.016\n",
      "[epoch 12, iter    40] loss: 44.220 eplased time 0.016\n",
      "[epoch 12, iter    50] loss: 51.587 eplased time 0.019\n",
      "[epoch 12, iter    60] loss: 47.753 eplased time 0.019\n",
      "[epoch 12, iter    70] loss: 49.420 eplased time 0.018\n",
      "[epoch 12, iter    80] loss: 51.104 eplased time 0.019\n",
      "[epoch 13, iter    10] loss: 53.493 eplased time 0.016\n",
      "[epoch 13, iter    20] loss: 47.617 eplased time 0.016\n",
      "[epoch 13, iter    30] loss: 48.742 eplased time 0.016\n",
      "[epoch 13, iter    40] loss: 49.917 eplased time 0.016\n",
      "[epoch 13, iter    50] loss: 46.429 eplased time 0.016\n",
      "[epoch 13, iter    60] loss: 49.068 eplased time 0.016\n",
      "[epoch 13, iter    70] loss: 50.135 eplased time 0.016\n",
      "[epoch 13, iter    80] loss: 49.591 eplased time 0.016\n",
      "[epoch 14, iter    10] loss: 48.414 eplased time 0.018\n",
      "[epoch 14, iter    20] loss: 45.662 eplased time 0.021\n",
      "[epoch 14, iter    30] loss: 52.141 eplased time 0.021\n",
      "[epoch 14, iter    40] loss: 56.506 eplased time 0.021\n",
      "[epoch 14, iter    50] loss: 45.888 eplased time 0.026\n",
      "[epoch 14, iter    60] loss: 46.949 eplased time 0.022\n",
      "[epoch 14, iter    70] loss: 49.046 eplased time 0.019\n",
      "[epoch 14, iter    80] loss: 49.040 eplased time 0.018\n",
      "[epoch 15, iter    10] loss: 52.741 eplased time 0.017\n",
      "[epoch 15, iter    20] loss: 49.636 eplased time 0.018\n",
      "[epoch 15, iter    30] loss: 49.242 eplased time 0.019\n",
      "[epoch 15, iter    40] loss: 48.845 eplased time 0.021\n",
      "[epoch 15, iter    50] loss: 44.684 eplased time 0.022\n",
      "[epoch 15, iter    60] loss: 48.430 eplased time 0.020\n",
      "[epoch 15, iter    70] loss: 46.969 eplased time 0.017\n",
      "[epoch 15, iter    80] loss: 48.950 eplased time 0.017\n",
      "[epoch 16, iter    10] loss: 49.522 eplased time 0.017\n",
      "[epoch 16, iter    20] loss: 44.807 eplased time 0.017\n",
      "[epoch 16, iter    30] loss: 48.416 eplased time 0.018\n",
      "[epoch 16, iter    40] loss: 53.289 eplased time 0.017\n",
      "[epoch 16, iter    50] loss: 53.245 eplased time 0.018\n",
      "[epoch 16, iter    60] loss: 44.400 eplased time 0.018\n",
      "[epoch 16, iter    70] loss: 48.341 eplased time 0.021\n",
      "[epoch 16, iter    80] loss: 44.656 eplased time 0.020\n",
      "[epoch 17, iter    10] loss: 50.030 eplased time 0.017\n",
      "[epoch 17, iter    20] loss: 47.879 eplased time 0.018\n",
      "[epoch 17, iter    30] loss: 44.918 eplased time 0.017\n",
      "[epoch 17, iter    40] loss: 46.072 eplased time 0.017\n",
      "[epoch 17, iter    50] loss: 46.809 eplased time 0.018\n",
      "[epoch 17, iter    60] loss: 49.182 eplased time 0.017\n",
      "[epoch 17, iter    70] loss: 49.881 eplased time 0.017\n",
      "[epoch 17, iter    80] loss: 49.366 eplased time 0.018\n",
      "[epoch 18, iter    10] loss: 50.872 eplased time 0.017\n",
      "[epoch 18, iter    20] loss: 45.719 eplased time 0.019\n",
      "[epoch 18, iter    30] loss: 51.468 eplased time 0.018\n",
      "[epoch 18, iter    40] loss: 46.711 eplased time 0.018\n",
      "[epoch 18, iter    50] loss: 43.467 eplased time 0.017\n",
      "[epoch 18, iter    60] loss: 49.012 eplased time 0.017\n",
      "[epoch 18, iter    70] loss: 43.591 eplased time 0.017\n",
      "[epoch 18, iter    80] loss: 50.212 eplased time 0.016\n",
      "[epoch 19, iter    10] loss: 48.556 eplased time 0.017\n",
      "[epoch 19, iter    20] loss: 44.093 eplased time 0.017\n",
      "[epoch 19, iter    30] loss: 49.956 eplased time 0.017\n",
      "[epoch 19, iter    40] loss: 46.569 eplased time 0.017\n",
      "[epoch 19, iter    50] loss: 49.392 eplased time 0.018\n",
      "[epoch 19, iter    60] loss: 49.918 eplased time 0.020\n",
      "[epoch 19, iter    70] loss: 42.313 eplased time 0.018\n",
      "[epoch 19, iter    80] loss: 44.846 eplased time 0.019\n",
      "[epoch 20, iter    10] loss: 44.487 eplased time 0.016\n",
      "[epoch 20, iter    20] loss: 46.482 eplased time 0.016\n",
      "[epoch 20, iter    30] loss: 44.768 eplased time 0.016\n",
      "[epoch 20, iter    40] loss: 47.455 eplased time 0.016\n",
      "[epoch 20, iter    50] loss: 49.848 eplased time 0.016\n",
      "[epoch 20, iter    60] loss: 48.325 eplased time 0.016\n",
      "[epoch 20, iter    70] loss: 49.234 eplased time 0.017\n",
      "[epoch 20, iter    80] loss: 44.255 eplased time 0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 21, iter    10] loss: 49.471 eplased time 0.018\n",
      "[epoch 21, iter    20] loss: 44.326 eplased time 0.020\n",
      "[epoch 21, iter    30] loss: 48.253 eplased time 0.018\n",
      "[epoch 21, iter    40] loss: 45.586 eplased time 0.018\n",
      "[epoch 21, iter    50] loss: 51.039 eplased time 0.016\n",
      "[epoch 21, iter    60] loss: 42.607 eplased time 0.016\n",
      "[epoch 21, iter    70] loss: 43.284 eplased time 0.016\n",
      "[epoch 21, iter    80] loss: 45.977 eplased time 0.016\n",
      "[epoch 22, iter    10] loss: 46.486 eplased time 0.016\n",
      "[epoch 22, iter    20] loss: 48.265 eplased time 0.016\n",
      "[epoch 22, iter    30] loss: 46.622 eplased time 0.016\n",
      "[epoch 22, iter    40] loss: 48.082 eplased time 0.016\n",
      "[epoch 22, iter    50] loss: 42.283 eplased time 0.018\n",
      "[epoch 22, iter    60] loss: 49.098 eplased time 0.020\n",
      "[epoch 22, iter    70] loss: 39.931 eplased time 0.017\n",
      "[epoch 22, iter    80] loss: 48.488 eplased time 0.017\n",
      "[epoch 23, iter    10] loss: 49.373 eplased time 0.016\n",
      "[epoch 23, iter    20] loss: 47.527 eplased time 0.017\n",
      "[epoch 23, iter    30] loss: 45.406 eplased time 0.016\n",
      "[epoch 23, iter    40] loss: 43.763 eplased time 0.016\n",
      "[epoch 23, iter    50] loss: 45.342 eplased time 0.016\n",
      "[epoch 23, iter    60] loss: 43.171 eplased time 0.016\n",
      "[epoch 23, iter    70] loss: 49.094 eplased time 0.018\n",
      "[epoch 23, iter    80] loss: 39.698 eplased time 0.016\n",
      "[epoch 24, iter    10] loss: 45.823 eplased time 0.018\n",
      "[epoch 24, iter    20] loss: 43.588 eplased time 0.017\n",
      "[epoch 24, iter    30] loss: 41.135 eplased time 0.017\n",
      "[epoch 24, iter    40] loss: 42.768 eplased time 0.020\n",
      "[epoch 24, iter    50] loss: 47.501 eplased time 0.016\n",
      "[epoch 24, iter    60] loss: 44.400 eplased time 0.016\n",
      "[epoch 24, iter    70] loss: 48.501 eplased time 0.016\n",
      "[epoch 24, iter    80] loss: 46.015 eplased time 0.016\n",
      "[epoch 25, iter    10] loss: 43.534 eplased time 0.016\n",
      "[epoch 25, iter    20] loss: 46.381 eplased time 0.016\n",
      "[epoch 25, iter    30] loss: 44.824 eplased time 0.016\n",
      "[epoch 25, iter    40] loss: 47.079 eplased time 0.016\n",
      "[epoch 25, iter    50] loss: 42.508 eplased time 0.016\n",
      "[epoch 25, iter    60] loss: 43.091 eplased time 0.021\n",
      "[epoch 25, iter    70] loss: 43.009 eplased time 0.017\n",
      "[epoch 25, iter    80] loss: 46.434 eplased time 0.016\n",
      "[epoch 26, iter    10] loss: 46.191 eplased time 0.016\n",
      "[epoch 26, iter    20] loss: 37.366 eplased time 0.016\n",
      "[epoch 26, iter    30] loss: 45.651 eplased time 0.016\n",
      "[epoch 26, iter    40] loss: 43.093 eplased time 0.016\n",
      "[epoch 26, iter    50] loss: 42.418 eplased time 0.016\n",
      "[epoch 26, iter    60] loss: 45.381 eplased time 0.016\n",
      "[epoch 26, iter    70] loss: 49.572 eplased time 0.016\n",
      "[epoch 26, iter    80] loss: 44.190 eplased time 0.016\n",
      "[epoch 27, iter    10] loss: 50.783 eplased time 0.018\n",
      "[epoch 27, iter    20] loss: 39.820 eplased time 0.017\n",
      "[epoch 27, iter    30] loss: 41.557 eplased time 0.019\n",
      "[epoch 27, iter    40] loss: 45.452 eplased time 0.018\n",
      "[epoch 27, iter    50] loss: 40.539 eplased time 0.021\n",
      "[epoch 27, iter    60] loss: 50.129 eplased time 0.016\n",
      "[epoch 27, iter    70] loss: 38.871 eplased time 0.016\n",
      "[epoch 27, iter    80] loss: 43.388 eplased time 0.017\n",
      "[epoch 28, iter    10] loss: 45.030 eplased time 0.017\n",
      "[epoch 28, iter    20] loss: 43.959 eplased time 0.016\n",
      "[epoch 28, iter    30] loss: 41.338 eplased time 0.016\n",
      "[epoch 28, iter    40] loss: 41.355 eplased time 0.016\n",
      "[epoch 28, iter    50] loss: 48.097 eplased time 0.016\n",
      "[epoch 28, iter    60] loss: 41.314 eplased time 0.018\n",
      "[epoch 28, iter    70] loss: 41.237 eplased time 0.021\n",
      "[epoch 28, iter    80] loss: 45.962 eplased time 0.017\n",
      "[epoch 29, iter    10] loss: 45.335 eplased time 0.016\n",
      "[epoch 29, iter    20] loss: 44.280 eplased time 0.016\n",
      "[epoch 29, iter    30] loss: 43.172 eplased time 0.019\n",
      "[epoch 29, iter    40] loss: 44.129 eplased time 0.018\n",
      "[epoch 29, iter    50] loss: 45.074 eplased time 0.016\n",
      "[epoch 29, iter    60] loss: 43.326 eplased time 0.019\n",
      "[epoch 29, iter    70] loss: 40.585 eplased time 0.016\n",
      "[epoch 29, iter    80] loss: 36.438 eplased time 0.016\n",
      "[epoch 30, iter    10] loss: 41.551 eplased time 0.016\n",
      "[epoch 30, iter    20] loss: 44.289 eplased time 0.020\n",
      "[epoch 30, iter    30] loss: 40.770 eplased time 0.018\n",
      "[epoch 30, iter    40] loss: 47.501 eplased time 0.017\n",
      "[epoch 30, iter    50] loss: 43.702 eplased time 0.021\n",
      "[epoch 30, iter    60] loss: 41.224 eplased time 0.017\n",
      "[epoch 30, iter    70] loss: 41.491 eplased time 0.017\n",
      "[epoch 30, iter    80] loss: 40.525 eplased time 0.017\n",
      "[epoch 31, iter    10] loss: 48.685 eplased time 0.017\n",
      "[epoch 31, iter    20] loss: 40.500 eplased time 0.017\n",
      "[epoch 31, iter    30] loss: 46.999 eplased time 0.017\n",
      "[epoch 31, iter    40] loss: 36.162 eplased time 0.016\n",
      "[epoch 31, iter    50] loss: 41.699 eplased time 0.016\n",
      "[epoch 31, iter    60] loss: 36.663 eplased time 0.018\n",
      "[epoch 31, iter    70] loss: 40.909 eplased time 0.020\n",
      "[epoch 31, iter    80] loss: 45.059 eplased time 0.017\n",
      "[epoch 32, iter    10] loss: 39.311 eplased time 0.020\n",
      "[epoch 32, iter    20] loss: 41.774 eplased time 0.016\n",
      "[epoch 32, iter    30] loss: 44.619 eplased time 0.016\n",
      "[epoch 32, iter    40] loss: 38.830 eplased time 0.020\n",
      "[epoch 32, iter    50] loss: 42.717 eplased time 0.016\n",
      "[epoch 32, iter    60] loss: 42.556 eplased time 0.016\n",
      "[epoch 32, iter    70] loss: 40.271 eplased time 0.016\n",
      "[epoch 32, iter    80] loss: 43.221 eplased time 0.019\n",
      "[epoch 33, iter    10] loss: 44.531 eplased time 0.015\n",
      "[epoch 33, iter    20] loss: 39.656 eplased time 0.021\n",
      "[epoch 33, iter    30] loss: 40.722 eplased time 0.018\n",
      "[epoch 33, iter    40] loss: 41.180 eplased time 0.018\n",
      "[epoch 33, iter    50] loss: 42.125 eplased time 0.016\n",
      "[epoch 33, iter    60] loss: 38.273 eplased time 0.016\n",
      "[epoch 33, iter    70] loss: 45.870 eplased time 0.020\n",
      "[epoch 33, iter    80] loss: 40.686 eplased time 0.016\n",
      "[epoch 34, iter    10] loss: 43.578 eplased time 0.016\n",
      "[epoch 34, iter    20] loss: 39.019 eplased time 0.016\n",
      "[epoch 34, iter    30] loss: 40.394 eplased time 0.019\n",
      "[epoch 34, iter    40] loss: 36.162 eplased time 0.016\n",
      "[epoch 34, iter    50] loss: 41.600 eplased time 0.016\n",
      "[epoch 34, iter    60] loss: 42.195 eplased time 0.017\n",
      "[epoch 34, iter    70] loss: 41.432 eplased time 0.018\n",
      "[epoch 34, iter    80] loss: 43.673 eplased time 0.019\n",
      "[epoch 35, iter    10] loss: 43.862 eplased time 0.017\n",
      "[epoch 35, iter    20] loss: 39.879 eplased time 0.016\n",
      "[epoch 35, iter    30] loss: 38.131 eplased time 0.016\n",
      "[epoch 35, iter    40] loss: 37.614 eplased time 0.019\n",
      "[epoch 35, iter    50] loss: 39.183 eplased time 0.020\n",
      "[epoch 35, iter    60] loss: 44.978 eplased time 0.019\n",
      "[epoch 35, iter    70] loss: 41.157 eplased time 0.017\n",
      "[epoch 35, iter    80] loss: 38.406 eplased time 0.016\n",
      "[epoch 36, iter    10] loss: 38.126 eplased time 0.016\n",
      "[epoch 36, iter    20] loss: 41.573 eplased time 0.019\n",
      "[epoch 36, iter    30] loss: 40.352 eplased time 0.019\n",
      "[epoch 36, iter    40] loss: 37.735 eplased time 0.021\n",
      "[epoch 36, iter    50] loss: 38.831 eplased time 0.016\n",
      "[epoch 36, iter    60] loss: 40.530 eplased time 0.016\n",
      "[epoch 36, iter    70] loss: 42.286 eplased time 0.016\n",
      "[epoch 36, iter    80] loss: 40.578 eplased time 0.016\n",
      "[epoch 37, iter    10] loss: 47.547 eplased time 0.017\n",
      "[epoch 37, iter    20] loss: 37.913 eplased time 0.016\n",
      "[epoch 37, iter    30] loss: 38.788 eplased time 0.017\n",
      "[epoch 37, iter    40] loss: 46.239 eplased time 0.019\n",
      "[epoch 37, iter    50] loss: 41.492 eplased time 0.018\n",
      "[epoch 37, iter    60] loss: 35.568 eplased time 0.018\n",
      "[epoch 37, iter    70] loss: 37.221 eplased time 0.020\n",
      "[epoch 37, iter    80] loss: 32.142 eplased time 0.019\n",
      "[epoch 38, iter    10] loss: 39.882 eplased time 0.016\n",
      "[epoch 38, iter    20] loss: 38.698 eplased time 0.016\n",
      "[epoch 38, iter    30] loss: 35.181 eplased time 0.016\n",
      "[epoch 38, iter    40] loss: 46.065 eplased time 0.017\n",
      "[epoch 38, iter    50] loss: 37.373 eplased time 0.017\n",
      "[epoch 38, iter    60] loss: 39.968 eplased time 0.016\n",
      "[epoch 38, iter    70] loss: 38.066 eplased time 0.016\n",
      "[epoch 38, iter    80] loss: 39.083 eplased time 0.017\n",
      "[epoch 39, iter    10] loss: 41.908 eplased time 0.016\n",
      "[epoch 39, iter    20] loss: 41.849 eplased time 0.018\n",
      "[epoch 39, iter    30] loss: 38.413 eplased time 0.020\n",
      "[epoch 39, iter    40] loss: 37.114 eplased time 0.018\n",
      "[epoch 39, iter    50] loss: 36.963 eplased time 0.017\n",
      "[epoch 39, iter    60] loss: 36.274 eplased time 0.016\n",
      "[epoch 39, iter    70] loss: 39.874 eplased time 0.016\n",
      "[epoch 39, iter    80] loss: 38.493 eplased time 0.016\n",
      "[epoch 40, iter    10] loss: 37.049 eplased time 0.016\n",
      "[epoch 40, iter    20] loss: 39.747 eplased time 0.016\n",
      "[epoch 40, iter    30] loss: 41.068 eplased time 0.017\n",
      "[epoch 40, iter    40] loss: 35.802 eplased time 0.017\n",
      "[epoch 40, iter    50] loss: 41.512 eplased time 0.016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 40, iter    60] loss: 38.494 eplased time 0.017\n",
      "[epoch 40, iter    70] loss: 37.940 eplased time 0.019\n",
      "[epoch 40, iter    80] loss: 37.269 eplased time 0.018\n",
      "[epoch 41, iter    10] loss: 40.815 eplased time 0.017\n",
      "[epoch 41, iter    20] loss: 37.183 eplased time 0.016\n",
      "[epoch 41, iter    30] loss: 40.737 eplased time 0.016\n",
      "[epoch 41, iter    40] loss: 39.469 eplased time 0.016\n",
      "[epoch 41, iter    50] loss: 42.904 eplased time 0.016\n",
      "[epoch 41, iter    60] loss: 35.572 eplased time 0.016\n",
      "[epoch 41, iter    70] loss: 31.994 eplased time 0.017\n",
      "[epoch 41, iter    80] loss: 38.015 eplased time 0.017\n",
      "[epoch 42, iter    10] loss: 36.106 eplased time 0.016\n",
      "[epoch 42, iter    20] loss: 32.107 eplased time 0.019\n",
      "[epoch 42, iter    30] loss: 38.797 eplased time 0.019\n",
      "[epoch 42, iter    40] loss: 42.228 eplased time 0.021\n",
      "[epoch 42, iter    50] loss: 38.429 eplased time 0.017\n",
      "[epoch 42, iter    60] loss: 41.853 eplased time 0.016\n",
      "[epoch 42, iter    70] loss: 33.635 eplased time 0.017\n",
      "[epoch 42, iter    80] loss: 39.467 eplased time 0.017\n",
      "[epoch 43, iter    10] loss: 39.829 eplased time 0.018\n",
      "[epoch 43, iter    20] loss: 40.862 eplased time 0.019\n",
      "[epoch 43, iter    30] loss: 42.346 eplased time 0.017\n",
      "[epoch 43, iter    40] loss: 39.186 eplased time 0.017\n",
      "[epoch 43, iter    50] loss: 31.069 eplased time 0.020\n",
      "[epoch 43, iter    60] loss: 35.222 eplased time 0.019\n",
      "[epoch 43, iter    70] loss: 34.178 eplased time 0.018\n",
      "[epoch 43, iter    80] loss: 36.483 eplased time 0.021\n",
      "[epoch 44, iter    10] loss: 34.252 eplased time 0.017\n",
      "[epoch 44, iter    20] loss: 33.141 eplased time 0.017\n",
      "[epoch 44, iter    30] loss: 35.429 eplased time 0.019\n",
      "[epoch 44, iter    40] loss: 37.799 eplased time 0.016\n",
      "[epoch 44, iter    50] loss: 39.333 eplased time 0.017\n",
      "[epoch 44, iter    60] loss: 38.163 eplased time 0.019\n",
      "[epoch 44, iter    70] loss: 40.022 eplased time 0.016\n",
      "[epoch 44, iter    80] loss: 40.474 eplased time 0.016\n",
      "[epoch 45, iter    10] loss: 42.229 eplased time 0.016\n",
      "[epoch 45, iter    20] loss: 34.235 eplased time 0.020\n",
      "[epoch 45, iter    30] loss: 36.417 eplased time 0.019\n",
      "[epoch 45, iter    40] loss: 36.741 eplased time 0.021\n",
      "[epoch 45, iter    50] loss: 32.304 eplased time 0.017\n",
      "[epoch 45, iter    60] loss: 37.562 eplased time 0.018\n",
      "[epoch 45, iter    70] loss: 35.626 eplased time 0.017\n",
      "[epoch 45, iter    80] loss: 37.433 eplased time 0.017\n",
      "[epoch 46, iter    10] loss: 33.200 eplased time 0.016\n",
      "[epoch 46, iter    20] loss: 37.830 eplased time 0.016\n",
      "[epoch 46, iter    30] loss: 37.304 eplased time 0.016\n",
      "[epoch 46, iter    40] loss: 34.700 eplased time 0.016\n",
      "[epoch 46, iter    50] loss: 40.729 eplased time 0.016\n",
      "[epoch 46, iter    60] loss: 41.371 eplased time 0.019\n",
      "[epoch 46, iter    70] loss: 32.706 eplased time 0.019\n",
      "[epoch 46, iter    80] loss: 32.276 eplased time 0.021\n",
      "[epoch 47, iter    10] loss: 31.666 eplased time 0.016\n",
      "[epoch 47, iter    20] loss: 31.447 eplased time 0.017\n",
      "[epoch 47, iter    30] loss: 35.672 eplased time 0.016\n",
      "[epoch 47, iter    40] loss: 36.425 eplased time 0.017\n",
      "[epoch 47, iter    50] loss: 43.173 eplased time 0.016\n",
      "[epoch 47, iter    60] loss: 37.734 eplased time 0.016\n",
      "[epoch 47, iter    70] loss: 36.672 eplased time 0.016\n",
      "[epoch 47, iter    80] loss: 36.606 eplased time 0.016\n",
      "[epoch 48, iter    10] loss: 32.818 eplased time 0.016\n",
      "[epoch 48, iter    20] loss: 39.960 eplased time 0.020\n",
      "[epoch 48, iter    30] loss: 32.618 eplased time 0.019\n",
      "[epoch 48, iter    40] loss: 35.806 eplased time 0.018\n",
      "[epoch 48, iter    50] loss: 34.290 eplased time 0.017\n",
      "[epoch 48, iter    60] loss: 41.491 eplased time 0.017\n",
      "[epoch 48, iter    70] loss: 39.377 eplased time 0.017\n",
      "[epoch 48, iter    80] loss: 31.201 eplased time 0.017\n",
      "[epoch 49, iter    10] loss: 32.217 eplased time 0.016\n",
      "[epoch 49, iter    20] loss: 35.431 eplased time 0.016\n",
      "[epoch 49, iter    30] loss: 38.889 eplased time 0.016\n",
      "[epoch 49, iter    40] loss: 36.171 eplased time 0.016\n",
      "[epoch 49, iter    50] loss: 39.756 eplased time 0.016\n",
      "[epoch 49, iter    60] loss: 34.374 eplased time 0.018\n",
      "[epoch 49, iter    70] loss: 31.054 eplased time 0.020\n",
      "[epoch 49, iter    80] loss: 33.680 eplased time 0.019\n",
      "[epoch 50, iter    10] loss: 33.735 eplased time 0.018\n",
      "[epoch 50, iter    20] loss: 35.984 eplased time 0.017\n",
      "[epoch 50, iter    30] loss: 30.934 eplased time 0.016\n",
      "[epoch 50, iter    40] loss: 36.842 eplased time 0.017\n",
      "[epoch 50, iter    50] loss: 35.790 eplased time 0.017\n",
      "[epoch 50, iter    60] loss: 29.166 eplased time 0.018\n",
      "[epoch 50, iter    70] loss: 43.363 eplased time 0.016\n",
      "[epoch 50, iter    80] loss: 34.980 eplased time 0.016\n",
      "[epoch 51, iter    10] loss: 34.656 eplased time 0.020\n",
      "[epoch 51, iter    20] loss: 31.490 eplased time 0.022\n",
      "[epoch 51, iter    30] loss: 35.491 eplased time 0.018\n",
      "[epoch 51, iter    40] loss: 35.957 eplased time 0.021\n",
      "[epoch 51, iter    50] loss: 31.846 eplased time 0.020\n",
      "[epoch 51, iter    60] loss: 35.085 eplased time 0.017\n",
      "[epoch 51, iter    70] loss: 37.724 eplased time 0.020\n",
      "[epoch 51, iter    80] loss: 34.881 eplased time 0.017\n",
      "[epoch 52, iter    10] loss: 36.891 eplased time 0.016\n",
      "[epoch 52, iter    20] loss: 33.599 eplased time 0.016\n",
      "[epoch 52, iter    30] loss: 31.091 eplased time 0.016\n",
      "[epoch 52, iter    40] loss: 40.210 eplased time 0.016\n",
      "[epoch 52, iter    50] loss: 32.230 eplased time 0.016\n",
      "[epoch 52, iter    60] loss: 30.075 eplased time 0.020\n",
      "[epoch 52, iter    70] loss: 36.273 eplased time 0.018\n",
      "[epoch 52, iter    80] loss: 34.237 eplased time 0.018\n",
      "[epoch 53, iter    10] loss: 34.797 eplased time 0.017\n",
      "[epoch 53, iter    20] loss: 37.830 eplased time 0.017\n",
      "[epoch 53, iter    30] loss: 34.294 eplased time 0.017\n",
      "[epoch 53, iter    40] loss: 33.376 eplased time 0.017\n",
      "[epoch 53, iter    50] loss: 39.327 eplased time 0.019\n",
      "[epoch 53, iter    60] loss: 28.533 eplased time 0.016\n",
      "[epoch 53, iter    70] loss: 33.004 eplased time 0.016\n",
      "[epoch 53, iter    80] loss: 30.982 eplased time 0.016\n",
      "[epoch 54, iter    10] loss: 32.318 eplased time 0.016\n",
      "[epoch 54, iter    20] loss: 29.309 eplased time 0.019\n",
      "[epoch 54, iter    30] loss: 34.506 eplased time 0.018\n",
      "[epoch 54, iter    40] loss: 33.644 eplased time 0.018\n",
      "[epoch 54, iter    50] loss: 34.259 eplased time 0.018\n",
      "[epoch 54, iter    60] loss: 33.239 eplased time 0.017\n",
      "[epoch 54, iter    70] loss: 37.800 eplased time 0.017\n",
      "[epoch 54, iter    80] loss: 36.207 eplased time 0.017\n",
      "[epoch 55, iter    10] loss: 34.508 eplased time 0.017\n",
      "[epoch 55, iter    20] loss: 29.415 eplased time 0.017\n",
      "[epoch 55, iter    30] loss: 29.143 eplased time 0.017\n",
      "[epoch 55, iter    40] loss: 32.953 eplased time 0.017\n",
      "[epoch 55, iter    50] loss: 36.098 eplased time 0.017\n",
      "[epoch 55, iter    60] loss: 37.779 eplased time 0.018\n",
      "[epoch 55, iter    70] loss: 35.321 eplased time 0.018\n",
      "[epoch 55, iter    80] loss: 31.534 eplased time 0.019\n",
      "[epoch 56, iter    10] loss: 31.761 eplased time 0.018\n",
      "[epoch 56, iter    20] loss: 32.870 eplased time 0.017\n",
      "[epoch 56, iter    30] loss: 31.833 eplased time 0.017\n",
      "[epoch 56, iter    40] loss: 32.157 eplased time 0.018\n",
      "[epoch 56, iter    50] loss: 39.749 eplased time 0.017\n",
      "[epoch 56, iter    60] loss: 33.210 eplased time 0.017\n",
      "[epoch 56, iter    70] loss: 35.090 eplased time 0.017\n",
      "[epoch 56, iter    80] loss: 28.030 eplased time 0.017\n",
      "[epoch 57, iter    10] loss: 31.712 eplased time 0.019\n",
      "[epoch 57, iter    20] loss: 33.687 eplased time 0.021\n",
      "[epoch 57, iter    30] loss: 31.102 eplased time 0.018\n",
      "[epoch 57, iter    40] loss: 33.122 eplased time 0.017\n",
      "[epoch 57, iter    50] loss: 35.221 eplased time 0.017\n",
      "[epoch 57, iter    60] loss: 32.272 eplased time 0.017\n",
      "[epoch 57, iter    70] loss: 34.928 eplased time 0.017\n",
      "[epoch 57, iter    80] loss: 28.689 eplased time 0.018\n",
      "[epoch 58, iter    10] loss: 37.609 eplased time 0.017\n",
      "[epoch 58, iter    20] loss: 32.747 eplased time 0.017\n",
      "[epoch 58, iter    30] loss: 28.904 eplased time 0.016\n",
      "[epoch 58, iter    40] loss: 32.432 eplased time 0.018\n",
      "[epoch 58, iter    50] loss: 27.577 eplased time 0.021\n",
      "[epoch 58, iter    60] loss: 36.378 eplased time 0.018\n",
      "[epoch 58, iter    70] loss: 30.553 eplased time 0.017\n",
      "[epoch 58, iter    80] loss: 31.729 eplased time 0.019\n",
      "[epoch 59, iter    10] loss: 35.030 eplased time 0.017\n",
      "[epoch 59, iter    20] loss: 29.602 eplased time 0.017\n",
      "[epoch 59, iter    30] loss: 29.181 eplased time 0.017\n",
      "[epoch 59, iter    40] loss: 32.971 eplased time 0.017\n",
      "[epoch 59, iter    50] loss: 29.934 eplased time 0.017\n",
      "[epoch 59, iter    60] loss: 34.332 eplased time 0.017\n",
      "[epoch 59, iter    70] loss: 31.959 eplased time 0.017\n",
      "[epoch 59, iter    80] loss: 33.692 eplased time 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 60, iter    10] loss: 30.250 eplased time 0.020\n",
      "[epoch 60, iter    20] loss: 36.756 eplased time 0.018\n",
      "[epoch 60, iter    30] loss: 31.154 eplased time 0.018\n",
      "[epoch 60, iter    40] loss: 30.549 eplased time 0.018\n",
      "[epoch 60, iter    50] loss: 33.800 eplased time 0.017\n",
      "[epoch 60, iter    60] loss: 28.576 eplased time 0.017\n",
      "[epoch 60, iter    70] loss: 29.568 eplased time 0.018\n",
      "[epoch 60, iter    80] loss: 32.925 eplased time 0.017\n",
      "[epoch 61, iter    10] loss: 32.231 eplased time 0.017\n",
      "[epoch 61, iter    20] loss: 30.148 eplased time 0.017\n",
      "[epoch 61, iter    30] loss: 32.608 eplased time 0.017\n",
      "[epoch 61, iter    40] loss: 31.216 eplased time 0.020\n",
      "[epoch 61, iter    50] loss: 29.744 eplased time 0.021\n",
      "[epoch 61, iter    60] loss: 33.293 eplased time 0.019\n",
      "[epoch 61, iter    70] loss: 30.256 eplased time 0.018\n",
      "[epoch 61, iter    80] loss: 34.190 eplased time 0.021\n",
      "[epoch 62, iter    10] loss: 32.930 eplased time 0.018\n",
      "[epoch 62, iter    20] loss: 31.667 eplased time 0.018\n",
      "[epoch 62, iter    30] loss: 30.575 eplased time 0.017\n",
      "[epoch 62, iter    40] loss: 32.712 eplased time 0.017\n",
      "[epoch 62, iter    50] loss: 27.691 eplased time 0.017\n",
      "[epoch 62, iter    60] loss: 30.238 eplased time 0.017\n",
      "[epoch 62, iter    70] loss: 29.949 eplased time 0.017\n",
      "[epoch 62, iter    80] loss: 35.101 eplased time 0.017\n",
      "[epoch 63, iter    10] loss: 34.926 eplased time 0.019\n",
      "[epoch 63, iter    20] loss: 36.006 eplased time 0.019\n",
      "[epoch 63, iter    30] loss: 31.715 eplased time 0.018\n",
      "[epoch 63, iter    40] loss: 26.899 eplased time 0.017\n",
      "[epoch 63, iter    50] loss: 29.417 eplased time 0.020\n",
      "[epoch 63, iter    60] loss: 26.422 eplased time 0.017\n",
      "[epoch 63, iter    70] loss: 26.008 eplased time 0.017\n",
      "[epoch 63, iter    80] loss: 36.126 eplased time 0.020\n",
      "[epoch 64, iter    10] loss: 30.496 eplased time 0.017\n",
      "[epoch 64, iter    20] loss: 30.312 eplased time 0.017\n",
      "[epoch 64, iter    30] loss: 31.947 eplased time 0.020\n",
      "[epoch 64, iter    40] loss: 29.136 eplased time 0.017\n",
      "[epoch 64, iter    50] loss: 27.819 eplased time 0.021\n",
      "[epoch 64, iter    60] loss: 31.456 eplased time 0.018\n",
      "[epoch 64, iter    70] loss: 35.324 eplased time 0.021\n",
      "[epoch 64, iter    80] loss: 28.029 eplased time 0.017\n",
      "[epoch 65, iter    10] loss: 28.218 eplased time 0.017\n",
      "[epoch 65, iter    20] loss: 32.290 eplased time 0.017\n",
      "[epoch 65, iter    30] loss: 34.096 eplased time 0.018\n",
      "[epoch 65, iter    40] loss: 31.533 eplased time 0.018\n",
      "[epoch 65, iter    50] loss: 28.258 eplased time 0.017\n",
      "[epoch 65, iter    60] loss: 32.965 eplased time 0.017\n",
      "[epoch 65, iter    70] loss: 32.386 eplased time 0.018\n",
      "[epoch 65, iter    80] loss: 21.338 eplased time 0.023\n",
      "[epoch 66, iter    10] loss: 31.258 eplased time 0.019\n",
      "[epoch 66, iter    20] loss: 29.720 eplased time 0.018\n",
      "[epoch 66, iter    30] loss: 33.153 eplased time 0.021\n",
      "[epoch 66, iter    40] loss: 27.194 eplased time 0.017\n",
      "[epoch 66, iter    50] loss: 31.108 eplased time 0.017\n",
      "[epoch 66, iter    60] loss: 30.141 eplased time 0.017\n",
      "[epoch 66, iter    70] loss: 30.261 eplased time 0.017\n",
      "[epoch 66, iter    80] loss: 28.187 eplased time 0.017\n",
      "[epoch 67, iter    10] loss: 34.311 eplased time 0.018\n",
      "[epoch 67, iter    20] loss: 31.863 eplased time 0.020\n",
      "[epoch 67, iter    30] loss: 29.787 eplased time 0.019\n",
      "[epoch 67, iter    40] loss: 29.078 eplased time 0.018\n",
      "[epoch 67, iter    50] loss: 31.118 eplased time 0.018\n",
      "[epoch 67, iter    60] loss: 26.808 eplased time 0.017\n",
      "[epoch 67, iter    70] loss: 23.738 eplased time 0.017\n",
      "[epoch 67, iter    80] loss: 31.410 eplased time 0.017\n",
      "[epoch 68, iter    10] loss: 29.342 eplased time 0.017\n",
      "[epoch 68, iter    20] loss: 30.785 eplased time 0.017\n",
      "[epoch 68, iter    30] loss: 23.801 eplased time 0.017\n",
      "[epoch 68, iter    40] loss: 35.368 eplased time 0.017\n",
      "[epoch 68, iter    50] loss: 29.654 eplased time 0.017\n",
      "[epoch 68, iter    60] loss: 33.851 eplased time 0.021\n",
      "[epoch 68, iter    70] loss: 26.806 eplased time 0.019\n",
      "[epoch 68, iter    80] loss: 27.291 eplased time 0.018\n",
      "[epoch 69, iter    10] loss: 29.165 eplased time 0.017\n",
      "[epoch 69, iter    20] loss: 29.223 eplased time 0.018\n",
      "[epoch 69, iter    30] loss: 26.937 eplased time 0.017\n",
      "[epoch 69, iter    40] loss: 29.095 eplased time 0.017\n",
      "[epoch 69, iter    50] loss: 28.940 eplased time 0.017\n",
      "[epoch 69, iter    60] loss: 32.473 eplased time 0.017\n",
      "[epoch 69, iter    70] loss: 29.629 eplased time 0.018\n",
      "[epoch 69, iter    80] loss: 28.513 eplased time 0.017\n",
      "[epoch 70, iter    10] loss: 32.883 eplased time 0.017\n",
      "[epoch 70, iter    20] loss: 28.026 eplased time 0.022\n",
      "[epoch 70, iter    30] loss: 28.513 eplased time 0.022\n",
      "[epoch 70, iter    40] loss: 27.554 eplased time 0.017\n",
      "[epoch 70, iter    50] loss: 31.600 eplased time 0.017\n",
      "[epoch 70, iter    60] loss: 26.884 eplased time 0.017\n",
      "[epoch 70, iter    70] loss: 29.206 eplased time 0.017\n",
      "[epoch 70, iter    80] loss: 27.288 eplased time 0.017\n",
      "[epoch 71, iter    10] loss: 25.902 eplased time 0.017\n",
      "[epoch 71, iter    20] loss: 27.744 eplased time 0.017\n",
      "[epoch 71, iter    30] loss: 26.413 eplased time 0.020\n",
      "[epoch 71, iter    40] loss: 30.375 eplased time 0.021\n",
      "[epoch 71, iter    50] loss: 30.261 eplased time 0.020\n",
      "[epoch 71, iter    60] loss: 31.052 eplased time 0.020\n",
      "[epoch 71, iter    70] loss: 30.784 eplased time 0.019\n",
      "[epoch 71, iter    80] loss: 27.845 eplased time 0.019\n",
      "[epoch 72, iter    10] loss: 28.463 eplased time 0.018\n",
      "[epoch 72, iter    20] loss: 27.151 eplased time 0.021\n",
      "[epoch 72, iter    30] loss: 28.272 eplased time 0.018\n",
      "[epoch 72, iter    40] loss: 28.973 eplased time 0.018\n",
      "[epoch 72, iter    50] loss: 29.728 eplased time 0.021\n",
      "[epoch 72, iter    60] loss: 27.242 eplased time 0.018\n",
      "[epoch 72, iter    70] loss: 31.640 eplased time 0.017\n",
      "[epoch 72, iter    80] loss: 28.780 eplased time 0.018\n",
      "[epoch 73, iter    10] loss: 24.877 eplased time 0.019\n",
      "[epoch 73, iter    20] loss: 24.790 eplased time 0.019\n",
      "[epoch 73, iter    30] loss: 30.617 eplased time 0.017\n",
      "[epoch 73, iter    40] loss: 29.808 eplased time 0.018\n",
      "[epoch 73, iter    50] loss: 30.535 eplased time 0.018\n",
      "[epoch 73, iter    60] loss: 29.275 eplased time 0.019\n",
      "[epoch 73, iter    70] loss: 28.185 eplased time 0.018\n",
      "[epoch 73, iter    80] loss: 29.964 eplased time 0.019\n",
      "[epoch 74, iter    10] loss: 25.889 eplased time 0.018\n",
      "[epoch 74, iter    20] loss: 26.915 eplased time 0.018\n",
      "[epoch 74, iter    30] loss: 30.870 eplased time 0.021\n",
      "[epoch 74, iter    40] loss: 28.021 eplased time 0.021\n",
      "[epoch 74, iter    50] loss: 27.223 eplased time 0.022\n",
      "[epoch 74, iter    60] loss: 29.423 eplased time 0.019\n",
      "[epoch 74, iter    70] loss: 32.095 eplased time 0.018\n",
      "[epoch 74, iter    80] loss: 26.396 eplased time 0.018\n",
      "[epoch 75, iter    10] loss: 29.355 eplased time 0.017\n",
      "[epoch 75, iter    20] loss: 30.684 eplased time 0.018\n",
      "[epoch 75, iter    30] loss: 28.807 eplased time 0.018\n",
      "[epoch 75, iter    40] loss: 29.375 eplased time 0.018\n",
      "[epoch 75, iter    50] loss: 24.562 eplased time 0.018\n",
      "[epoch 75, iter    60] loss: 29.104 eplased time 0.021\n",
      "[epoch 75, iter    70] loss: 26.715 eplased time 0.024\n",
      "[epoch 75, iter    80] loss: 27.260 eplased time 0.024\n",
      "[epoch 76, iter    10] loss: 24.809 eplased time 0.019\n",
      "[epoch 76, iter    20] loss: 30.437 eplased time 0.018\n",
      "[epoch 76, iter    30] loss: 27.491 eplased time 0.018\n",
      "[epoch 76, iter    40] loss: 29.969 eplased time 0.017\n",
      "[epoch 76, iter    50] loss: 27.410 eplased time 0.018\n",
      "[epoch 76, iter    60] loss: 26.044 eplased time 0.018\n",
      "[epoch 76, iter    70] loss: 27.139 eplased time 0.018\n",
      "[epoch 76, iter    80] loss: 30.374 eplased time 0.020\n",
      "[epoch 77, iter    10] loss: 26.252 eplased time 0.023\n",
      "[epoch 77, iter    20] loss: 27.455 eplased time 0.022\n",
      "[epoch 77, iter    30] loss: 33.038 eplased time 0.020\n",
      "[epoch 77, iter    40] loss: 25.093 eplased time 0.020\n",
      "[epoch 77, iter    50] loss: 25.604 eplased time 0.020\n",
      "[epoch 77, iter    60] loss: 24.208 eplased time 0.018\n",
      "[epoch 77, iter    70] loss: 27.535 eplased time 0.018\n",
      "[epoch 77, iter    80] loss: 32.387 eplased time 0.021\n",
      "[epoch 78, iter    10] loss: 23.082 eplased time 0.018\n",
      "[epoch 78, iter    20] loss: 28.910 eplased time 0.019\n",
      "[epoch 78, iter    30] loss: 26.618 eplased time 0.020\n",
      "[epoch 78, iter    40] loss: 25.678 eplased time 0.019\n",
      "[epoch 78, iter    50] loss: 24.602 eplased time 0.018\n",
      "[epoch 78, iter    60] loss: 28.677 eplased time 0.018\n",
      "[epoch 78, iter    70] loss: 30.443 eplased time 0.018\n",
      "[epoch 78, iter    80] loss: 32.322 eplased time 0.018\n",
      "[epoch 79, iter    10] loss: 31.191 eplased time 0.017\n",
      "[epoch 79, iter    20] loss: 24.910 eplased time 0.018\n",
      "[epoch 79, iter    30] loss: 29.060 eplased time 0.017\n",
      "[epoch 79, iter    40] loss: 28.873 eplased time 0.017\n",
      "[epoch 79, iter    50] loss: 25.816 eplased time 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 79, iter    60] loss: 29.397 eplased time 0.021\n",
      "[epoch 79, iter    70] loss: 24.378 eplased time 0.019\n",
      "[epoch 79, iter    80] loss: 25.376 eplased time 0.020\n",
      "[epoch 80, iter    10] loss: 31.397 eplased time 0.017\n",
      "[epoch 80, iter    20] loss: 26.955 eplased time 0.017\n",
      "[epoch 80, iter    30] loss: 29.151 eplased time 0.017\n",
      "[epoch 80, iter    40] loss: 23.066 eplased time 0.017\n",
      "[epoch 80, iter    50] loss: 29.149 eplased time 0.017\n",
      "[epoch 80, iter    60] loss: 29.348 eplased time 0.018\n",
      "[epoch 80, iter    70] loss: 23.028 eplased time 0.017\n",
      "[epoch 80, iter    80] loss: 24.010 eplased time 0.017\n",
      "[epoch 81, iter    10] loss: 27.405 eplased time 0.017\n",
      "[epoch 81, iter    20] loss: 29.785 eplased time 0.023\n",
      "[epoch 81, iter    30] loss: 26.152 eplased time 0.019\n",
      "[epoch 81, iter    40] loss: 26.930 eplased time 0.021\n",
      "[epoch 81, iter    50] loss: 22.517 eplased time 0.018\n",
      "[epoch 81, iter    60] loss: 27.937 eplased time 0.018\n",
      "[epoch 81, iter    70] loss: 26.563 eplased time 0.020\n",
      "[epoch 81, iter    80] loss: 27.278 eplased time 0.021\n",
      "[epoch 82, iter    10] loss: 29.921 eplased time 0.019\n",
      "[epoch 82, iter    20] loss: 25.342 eplased time 0.018\n",
      "[epoch 82, iter    30] loss: 27.255 eplased time 0.018\n",
      "[epoch 82, iter    40] loss: 23.518 eplased time 0.018\n",
      "[epoch 82, iter    50] loss: 20.985 eplased time 0.020\n",
      "[epoch 82, iter    60] loss: 28.723 eplased time 0.020\n",
      "[epoch 82, iter    70] loss: 29.791 eplased time 0.019\n",
      "[epoch 82, iter    80] loss: 28.101 eplased time 0.018\n",
      "[epoch 83, iter    10] loss: 24.935 eplased time 0.018\n",
      "[epoch 83, iter    20] loss: 30.667 eplased time 0.018\n",
      "[epoch 83, iter    30] loss: 30.003 eplased time 0.018\n",
      "[epoch 83, iter    40] loss: 23.916 eplased time 0.021\n",
      "[epoch 83, iter    50] loss: 23.379 eplased time 0.018\n",
      "[epoch 83, iter    60] loss: 27.152 eplased time 0.021\n",
      "[epoch 83, iter    70] loss: 24.701 eplased time 0.018\n",
      "[epoch 83, iter    80] loss: 25.727 eplased time 0.021\n",
      "[epoch 84, iter    10] loss: 25.649 eplased time 0.020\n",
      "[epoch 84, iter    20] loss: 27.799 eplased time 0.021\n",
      "[epoch 84, iter    30] loss: 24.334 eplased time 0.018\n",
      "[epoch 84, iter    40] loss: 25.041 eplased time 0.019\n",
      "[epoch 84, iter    50] loss: 29.684 eplased time 0.020\n",
      "[epoch 84, iter    60] loss: 28.278 eplased time 0.020\n",
      "[epoch 84, iter    70] loss: 25.994 eplased time 0.020\n",
      "[epoch 84, iter    80] loss: 24.996 eplased time 0.018\n",
      "[epoch 85, iter    10] loss: 28.421 eplased time 0.018\n",
      "[epoch 85, iter    20] loss: 23.802 eplased time 0.018\n",
      "[epoch 85, iter    30] loss: 30.846 eplased time 0.020\n",
      "[epoch 85, iter    40] loss: 23.237 eplased time 0.019\n",
      "[epoch 85, iter    50] loss: 26.819 eplased time 0.022\n",
      "[epoch 85, iter    60] loss: 26.234 eplased time 0.018\n",
      "[epoch 85, iter    70] loss: 23.629 eplased time 0.018\n",
      "[epoch 85, iter    80] loss: 25.564 eplased time 0.018\n",
      "[epoch 86, iter    10] loss: 23.107 eplased time 0.018\n",
      "[epoch 86, iter    20] loss: 25.692 eplased time 0.018\n",
      "[epoch 86, iter    30] loss: 24.702 eplased time 0.018\n",
      "[epoch 86, iter    40] loss: 21.938 eplased time 0.018\n",
      "[epoch 86, iter    50] loss: 30.809 eplased time 0.021\n",
      "[epoch 86, iter    60] loss: 24.807 eplased time 0.021\n",
      "[epoch 86, iter    70] loss: 30.179 eplased time 0.020\n",
      "[epoch 86, iter    80] loss: 26.220 eplased time 0.021\n",
      "[epoch 87, iter    10] loss: 27.668 eplased time 0.018\n",
      "[epoch 87, iter    20] loss: 22.737 eplased time 0.018\n",
      "[epoch 87, iter    30] loss: 24.921 eplased time 0.018\n",
      "[epoch 87, iter    40] loss: 24.736 eplased time 0.018\n",
      "[epoch 87, iter    50] loss: 23.499 eplased time 0.018\n",
      "[epoch 87, iter    60] loss: 23.560 eplased time 0.018\n",
      "[epoch 87, iter    70] loss: 29.948 eplased time 0.018\n",
      "[epoch 87, iter    80] loss: 29.424 eplased time 0.021\n",
      "[epoch 88, iter    10] loss: 27.087 eplased time 0.020\n",
      "[epoch 88, iter    20] loss: 25.239 eplased time 0.020\n",
      "[epoch 88, iter    30] loss: 24.842 eplased time 0.023\n",
      "[epoch 88, iter    40] loss: 24.862 eplased time 0.018\n",
      "[epoch 88, iter    50] loss: 23.721 eplased time 0.018\n",
      "[epoch 88, iter    60] loss: 26.180 eplased time 0.018\n",
      "[epoch 88, iter    70] loss: 28.351 eplased time 0.018\n",
      "[epoch 88, iter    80] loss: 25.627 eplased time 0.021\n",
      "[epoch 89, iter    10] loss: 25.167 eplased time 0.019\n",
      "[epoch 89, iter    20] loss: 25.709 eplased time 0.021\n",
      "[epoch 89, iter    30] loss: 21.943 eplased time 0.018\n",
      "[epoch 89, iter    40] loss: 22.617 eplased time 0.021\n",
      "[epoch 89, iter    50] loss: 28.678 eplased time 0.019\n",
      "[epoch 89, iter    60] loss: 22.707 eplased time 0.019\n",
      "[epoch 89, iter    70] loss: 26.506 eplased time 0.022\n",
      "[epoch 89, iter    80] loss: 29.576 eplased time 0.018\n",
      "[epoch 90, iter    10] loss: 24.930 eplased time 0.018\n",
      "[epoch 90, iter    20] loss: 22.741 eplased time 0.018\n",
      "[epoch 90, iter    30] loss: 29.753 eplased time 0.018\n",
      "[epoch 90, iter    40] loss: 24.809 eplased time 0.018\n",
      "[epoch 90, iter    50] loss: 25.845 eplased time 0.017\n",
      "[epoch 90, iter    60] loss: 24.507 eplased time 0.021\n",
      "[epoch 90, iter    70] loss: 23.859 eplased time 0.020\n",
      "[epoch 90, iter    80] loss: 25.717 eplased time 0.019\n",
      "[epoch 91, iter    10] loss: 23.104 eplased time 0.018\n",
      "[epoch 91, iter    20] loss: 25.035 eplased time 0.018\n",
      "[epoch 91, iter    30] loss: 26.965 eplased time 0.019\n",
      "[epoch 91, iter    40] loss: 22.811 eplased time 0.020\n",
      "[epoch 91, iter    50] loss: 26.280 eplased time 0.018\n",
      "[epoch 91, iter    60] loss: 28.126 eplased time 0.018\n",
      "[epoch 91, iter    70] loss: 23.211 eplased time 0.018\n",
      "[epoch 91, iter    80] loss: 24.796 eplased time 0.018\n",
      "[epoch 92, iter    10] loss: 24.211 eplased time 0.018\n",
      "[epoch 92, iter    20] loss: 25.265 eplased time 0.021\n",
      "[epoch 92, iter    30] loss: 24.457 eplased time 0.020\n",
      "[epoch 92, iter    40] loss: 25.519 eplased time 0.019\n",
      "[epoch 92, iter    50] loss: 28.216 eplased time 0.018\n",
      "[epoch 92, iter    60] loss: 23.319 eplased time 0.018\n",
      "[epoch 92, iter    70] loss: 23.194 eplased time 0.018\n",
      "[epoch 92, iter    80] loss: 24.849 eplased time 0.018\n",
      "[epoch 93, iter    10] loss: 23.619 eplased time 0.018\n",
      "[epoch 93, iter    20] loss: 23.253 eplased time 0.018\n",
      "[epoch 93, iter    30] loss: 23.840 eplased time 0.018\n",
      "[epoch 93, iter    40] loss: 26.410 eplased time 0.018\n",
      "[epoch 93, iter    50] loss: 23.332 eplased time 0.017\n",
      "[epoch 93, iter    60] loss: 23.086 eplased time 0.023\n",
      "[epoch 93, iter    70] loss: 25.838 eplased time 0.019\n",
      "[epoch 93, iter    80] loss: 28.178 eplased time 0.021\n",
      "[epoch 94, iter    10] loss: 23.964 eplased time 0.018\n",
      "[epoch 94, iter    20] loss: 24.371 eplased time 0.018\n",
      "[epoch 94, iter    30] loss: 25.072 eplased time 0.018\n",
      "[epoch 94, iter    40] loss: 21.899 eplased time 0.018\n",
      "[epoch 94, iter    50] loss: 26.892 eplased time 0.018\n",
      "[epoch 94, iter    60] loss: 26.450 eplased time 0.019\n",
      "[epoch 94, iter    70] loss: 22.359 eplased time 0.023\n",
      "[epoch 94, iter    80] loss: 26.135 eplased time 0.018\n",
      "[epoch 95, iter    10] loss: 27.507 eplased time 0.021\n",
      "[epoch 95, iter    20] loss: 20.435 eplased time 0.020\n",
      "[epoch 95, iter    30] loss: 23.009 eplased time 0.021\n",
      "[epoch 95, iter    40] loss: 24.301 eplased time 0.019\n",
      "[epoch 95, iter    50] loss: 24.746 eplased time 0.018\n",
      "[epoch 95, iter    60] loss: 29.656 eplased time 0.018\n",
      "[epoch 95, iter    70] loss: 22.097 eplased time 0.018\n",
      "[epoch 95, iter    80] loss: 23.354 eplased time 0.018\n",
      "[epoch 96, iter    10] loss: 25.102 eplased time 0.018\n",
      "[epoch 96, iter    20] loss: 23.365 eplased time 0.018\n",
      "[epoch 96, iter    30] loss: 28.225 eplased time 0.018\n",
      "[epoch 96, iter    40] loss: 24.970 eplased time 0.020\n",
      "[epoch 96, iter    50] loss: 21.071 eplased time 0.021\n",
      "[epoch 96, iter    60] loss: 23.719 eplased time 0.019\n",
      "[epoch 96, iter    70] loss: 19.511 eplased time 0.019\n",
      "[epoch 96, iter    80] loss: 28.159 eplased time 0.018\n",
      "[epoch 97, iter    10] loss: 24.825 eplased time 0.018\n",
      "[epoch 97, iter    20] loss: 24.088 eplased time 0.018\n",
      "[epoch 97, iter    30] loss: 25.122 eplased time 0.018\n",
      "[epoch 97, iter    40] loss: 24.598 eplased time 0.018\n",
      "[epoch 97, iter    50] loss: 25.016 eplased time 0.018\n",
      "[epoch 97, iter    60] loss: 20.726 eplased time 0.018\n",
      "[epoch 97, iter    70] loss: 23.560 eplased time 0.020\n",
      "[epoch 97, iter    80] loss: 24.568 eplased time 0.020\n",
      "[epoch 98, iter    10] loss: 24.753 eplased time 0.022\n",
      "[epoch 98, iter    20] loss: 22.271 eplased time 0.022\n",
      "[epoch 98, iter    30] loss: 26.798 eplased time 0.026\n",
      "[epoch 98, iter    40] loss: 22.068 eplased time 0.028\n",
      "[epoch 98, iter    50] loss: 26.584 eplased time 0.026\n",
      "[epoch 98, iter    60] loss: 21.555 eplased time 0.023\n",
      "[epoch 98, iter    70] loss: 24.674 eplased time 0.024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 98, iter    80] loss: 24.385 eplased time 0.024\n",
      "[epoch 99, iter    10] loss: 25.639 eplased time 0.023\n",
      "[epoch 99, iter    20] loss: 26.447 eplased time 0.019\n",
      "[epoch 99, iter    30] loss: 25.100 eplased time 0.019\n",
      "[epoch 99, iter    40] loss: 23.570 eplased time 0.018\n",
      "[epoch 99, iter    50] loss: 19.889 eplased time 0.019\n",
      "[epoch 99, iter    60] loss: 26.124 eplased time 0.018\n",
      "[epoch 99, iter    70] loss: 23.356 eplased time 0.018\n",
      "[epoch 99, iter    80] loss: 19.990 eplased time 0.018\n",
      "[epoch 100, iter    10] loss: 21.153 eplased time 0.018\n",
      "[epoch 100, iter    20] loss: 26.664 eplased time 0.018\n",
      "[epoch 100, iter    30] loss: 25.434 eplased time 0.023\n",
      "[epoch 100, iter    40] loss: 25.856 eplased time 0.021\n",
      "[epoch 100, iter    50] loss: 23.472 eplased time 0.023\n",
      "[epoch 100, iter    60] loss: 24.921 eplased time 0.019\n",
      "[epoch 100, iter    70] loss: 22.091 eplased time 0.022\n",
      "[epoch 100, iter    80] loss: 20.195 eplased time 0.019\n",
      "[epoch 101, iter    10] loss: 26.170 eplased time 0.019\n",
      "[epoch 101, iter    20] loss: 21.700 eplased time 0.018\n",
      "[epoch 101, iter    30] loss: 25.999 eplased time 0.018\n",
      "[epoch 101, iter    40] loss: 23.216 eplased time 0.021\n",
      "[epoch 101, iter    50] loss: 21.425 eplased time 0.020\n",
      "[epoch 101, iter    60] loss: 23.807 eplased time 0.023\n",
      "[epoch 101, iter    70] loss: 20.417 eplased time 0.022\n",
      "[epoch 101, iter    80] loss: 25.812 eplased time 0.022\n",
      "[epoch 102, iter    10] loss: 27.941 eplased time 0.019\n",
      "[epoch 102, iter    20] loss: 24.659 eplased time 0.019\n",
      "[epoch 102, iter    30] loss: 26.581 eplased time 0.019\n",
      "[epoch 102, iter    40] loss: 22.760 eplased time 0.019\n",
      "[epoch 102, iter    50] loss: 20.699 eplased time 0.019\n",
      "[epoch 102, iter    60] loss: 23.078 eplased time 0.019\n",
      "[epoch 102, iter    70] loss: 20.346 eplased time 0.018\n",
      "[epoch 102, iter    80] loss: 22.218 eplased time 0.023\n",
      "[epoch 103, iter    10] loss: 25.516 eplased time 0.020\n",
      "[epoch 103, iter    20] loss: 20.621 eplased time 0.018\n",
      "[epoch 103, iter    30] loss: 21.484 eplased time 0.019\n",
      "[epoch 103, iter    40] loss: 26.424 eplased time 0.018\n",
      "[epoch 103, iter    50] loss: 22.701 eplased time 0.018\n",
      "[epoch 103, iter    60] loss: 25.856 eplased time 0.018\n",
      "[epoch 103, iter    70] loss: 23.320 eplased time 0.018\n",
      "[epoch 103, iter    80] loss: 19.365 eplased time 0.019\n",
      "[epoch 104, iter    10] loss: 21.821 eplased time 0.018\n",
      "[epoch 104, iter    20] loss: 21.926 eplased time 0.018\n",
      "[epoch 104, iter    30] loss: 24.533 eplased time 0.021\n",
      "[epoch 104, iter    40] loss: 24.890 eplased time 0.020\n",
      "[epoch 104, iter    50] loss: 21.554 eplased time 0.019\n",
      "[epoch 104, iter    60] loss: 23.764 eplased time 0.021\n",
      "[epoch 104, iter    70] loss: 22.606 eplased time 0.018\n",
      "[epoch 104, iter    80] loss: 23.607 eplased time 0.019\n",
      "[epoch 105, iter    10] loss: 24.633 eplased time 0.022\n",
      "[epoch 105, iter    20] loss: 22.249 eplased time 0.018\n",
      "[epoch 105, iter    30] loss: 20.492 eplased time 0.019\n",
      "[epoch 105, iter    40] loss: 23.956 eplased time 0.018\n",
      "[epoch 105, iter    50] loss: 22.990 eplased time 0.019\n",
      "[epoch 105, iter    60] loss: 23.629 eplased time 0.024\n",
      "[epoch 105, iter    70] loss: 29.304 eplased time 0.020\n",
      "[epoch 105, iter    80] loss: 18.355 eplased time 0.020\n",
      "[epoch 106, iter    10] loss: 23.722 eplased time 0.018\n",
      "[epoch 106, iter    20] loss: 22.952 eplased time 0.022\n",
      "[epoch 106, iter    30] loss: 22.922 eplased time 0.019\n",
      "[epoch 106, iter    40] loss: 23.054 eplased time 0.020\n",
      "[epoch 106, iter    50] loss: 23.800 eplased time 0.019\n",
      "[epoch 106, iter    60] loss: 24.431 eplased time 0.019\n",
      "[epoch 106, iter    70] loss: 20.417 eplased time 0.018\n",
      "[epoch 106, iter    80] loss: 22.638 eplased time 0.018\n",
      "[epoch 107, iter    10] loss: 22.511 eplased time 0.020\n",
      "[epoch 107, iter    20] loss: 23.484 eplased time 0.020\n",
      "[epoch 107, iter    30] loss: 23.893 eplased time 0.020\n",
      "[epoch 107, iter    40] loss: 22.964 eplased time 0.018\n",
      "[epoch 107, iter    50] loss: 22.915 eplased time 0.018\n",
      "[epoch 107, iter    60] loss: 23.643 eplased time 0.019\n",
      "[epoch 107, iter    70] loss: 21.024 eplased time 0.018\n",
      "[epoch 107, iter    80] loss: 22.634 eplased time 0.019\n",
      "[epoch 108, iter    10] loss: 23.678 eplased time 0.018\n",
      "[epoch 108, iter    20] loss: 26.722 eplased time 0.019\n",
      "[epoch 108, iter    30] loss: 17.872 eplased time 0.018\n",
      "[epoch 108, iter    40] loss: 22.327 eplased time 0.021\n",
      "[epoch 108, iter    50] loss: 22.172 eplased time 0.020\n",
      "[epoch 108, iter    60] loss: 21.012 eplased time 0.019\n",
      "[epoch 108, iter    70] loss: 24.121 eplased time 0.019\n",
      "[epoch 108, iter    80] loss: 22.997 eplased time 0.018\n",
      "[epoch 109, iter    10] loss: 23.957 eplased time 0.019\n",
      "[epoch 109, iter    20] loss: 24.498 eplased time 0.019\n",
      "[epoch 109, iter    30] loss: 22.698 eplased time 0.022\n",
      "[epoch 109, iter    40] loss: 22.223 eplased time 0.018\n",
      "[epoch 109, iter    50] loss: 21.864 eplased time 0.018\n",
      "[epoch 109, iter    60] loss: 20.424 eplased time 0.019\n",
      "[epoch 109, iter    70] loss: 22.027 eplased time 0.023\n",
      "[epoch 109, iter    80] loss: 22.509 eplased time 0.021\n",
      "[epoch 110, iter    10] loss: 26.898 eplased time 0.021\n",
      "[epoch 110, iter    20] loss: 21.166 eplased time 0.018\n",
      "[epoch 110, iter    30] loss: 20.865 eplased time 0.020\n",
      "[epoch 110, iter    40] loss: 20.985 eplased time 0.019\n",
      "[epoch 110, iter    50] loss: 21.440 eplased time 0.021\n",
      "[epoch 110, iter    60] loss: 21.510 eplased time 0.021\n",
      "[epoch 110, iter    70] loss: 24.732 eplased time 0.026\n",
      "[epoch 110, iter    80] loss: 21.067 eplased time 0.029\n",
      "[epoch 111, iter    10] loss: 26.517 eplased time 0.028\n",
      "[epoch 111, iter    20] loss: 24.071 eplased time 0.031\n",
      "[epoch 111, iter    30] loss: 21.700 eplased time 0.026\n",
      "[epoch 111, iter    40] loss: 24.884 eplased time 0.022\n",
      "[epoch 111, iter    50] loss: 21.484 eplased time 0.019\n",
      "[epoch 111, iter    60] loss: 20.880 eplased time 0.022\n",
      "[epoch 111, iter    70] loss: 19.726 eplased time 0.021\n",
      "[epoch 111, iter    80] loss: 20.873 eplased time 0.019\n",
      "[epoch 112, iter    10] loss: 18.054 eplased time 0.019\n",
      "[epoch 112, iter    20] loss: 25.407 eplased time 0.019\n",
      "[epoch 112, iter    30] loss: 19.811 eplased time 0.022\n",
      "[epoch 112, iter    40] loss: 24.473 eplased time 0.023\n",
      "[epoch 112, iter    50] loss: 22.102 eplased time 0.019\n",
      "[epoch 112, iter    60] loss: 19.299 eplased time 0.022\n",
      "[epoch 112, iter    70] loss: 26.890 eplased time 0.019\n",
      "[epoch 112, iter    80] loss: 22.697 eplased time 0.019\n",
      "[epoch 113, iter    10] loss: 19.996 eplased time 0.022\n",
      "[epoch 113, iter    20] loss: 23.121 eplased time 0.019\n",
      "[epoch 113, iter    30] loss: 20.174 eplased time 0.021\n",
      "[epoch 113, iter    40] loss: 23.148 eplased time 0.019\n",
      "[epoch 113, iter    50] loss: 23.550 eplased time 0.019\n",
      "[epoch 113, iter    60] loss: 23.044 eplased time 0.021\n",
      "[epoch 113, iter    70] loss: 22.800 eplased time 0.023\n",
      "[epoch 113, iter    80] loss: 21.873 eplased time 0.021\n",
      "[epoch 114, iter    10] loss: 23.275 eplased time 0.019\n",
      "[epoch 114, iter    20] loss: 19.415 eplased time 0.019\n",
      "[epoch 114, iter    30] loss: 25.337 eplased time 0.019\n",
      "[epoch 114, iter    40] loss: 21.048 eplased time 0.019\n",
      "[epoch 114, iter    50] loss: 19.881 eplased time 0.020\n",
      "[epoch 114, iter    60] loss: 23.340 eplased time 0.019\n",
      "[epoch 114, iter    70] loss: 19.023 eplased time 0.020\n",
      "[epoch 114, iter    80] loss: 24.981 eplased time 0.023\n",
      "[epoch 115, iter    10] loss: 19.838 eplased time 0.022\n",
      "[epoch 115, iter    20] loss: 20.376 eplased time 0.021\n",
      "[epoch 115, iter    30] loss: 23.026 eplased time 0.019\n",
      "[epoch 115, iter    40] loss: 23.155 eplased time 0.019\n",
      "[epoch 115, iter    50] loss: 19.734 eplased time 0.019\n",
      "[epoch 115, iter    60] loss: 24.519 eplased time 0.020\n",
      "[epoch 115, iter    70] loss: 21.735 eplased time 0.022\n",
      "[epoch 115, iter    80] loss: 23.704 eplased time 0.019\n",
      "[epoch 116, iter    10] loss: 22.563 eplased time 0.020\n",
      "[epoch 116, iter    20] loss: 24.357 eplased time 0.023\n",
      "[epoch 116, iter    30] loss: 19.811 eplased time 0.021\n",
      "[epoch 116, iter    40] loss: 21.260 eplased time 0.018\n",
      "[epoch 116, iter    50] loss: 20.119 eplased time 0.018\n",
      "[epoch 116, iter    60] loss: 22.595 eplased time 0.019\n",
      "[epoch 116, iter    70] loss: 25.695 eplased time 0.019\n",
      "[epoch 116, iter    80] loss: 19.968 eplased time 0.019\n",
      "[epoch 117, iter    10] loss: 24.418 eplased time 0.019\n",
      "[epoch 117, iter    20] loss: 22.912 eplased time 0.019\n",
      "[epoch 117, iter    30] loss: 20.371 eplased time 0.019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 117, iter    40] loss: 21.145 eplased time 0.023\n",
      "[epoch 117, iter    50] loss: 23.982 eplased time 0.023\n",
      "[epoch 117, iter    60] loss: 18.658 eplased time 0.022\n",
      "[epoch 117, iter    70] loss: 19.215 eplased time 0.019\n",
      "[epoch 117, iter    80] loss: 22.290 eplased time 0.019\n",
      "[epoch 118, iter    10] loss: 19.577 eplased time 0.019\n",
      "[epoch 118, iter    20] loss: 24.280 eplased time 0.020\n",
      "[epoch 118, iter    30] loss: 22.772 eplased time 0.021\n",
      "[epoch 118, iter    40] loss: 23.040 eplased time 0.020\n",
      "[epoch 118, iter    50] loss: 19.009 eplased time 0.019\n",
      "[epoch 118, iter    60] loss: 19.814 eplased time 0.021\n",
      "[epoch 118, iter    70] loss: 21.797 eplased time 0.024\n",
      "[epoch 118, iter    80] loss: 24.782 eplased time 0.022\n",
      "[epoch 119, iter    10] loss: 20.921 eplased time 0.019\n",
      "[epoch 119, iter    20] loss: 24.570 eplased time 0.019\n",
      "[epoch 119, iter    30] loss: 22.294 eplased time 0.019\n",
      "[epoch 119, iter    40] loss: 20.975 eplased time 0.024\n",
      "[epoch 119, iter    50] loss: 21.320 eplased time 0.021\n",
      "[epoch 119, iter    60] loss: 22.992 eplased time 0.020\n",
      "[epoch 119, iter    70] loss: 18.628 eplased time 0.021\n",
      "[epoch 119, iter    80] loss: 22.310 eplased time 0.022\n",
      "[epoch 120, iter    10] loss: 24.990 eplased time 0.023\n",
      "[epoch 120, iter    20] loss: 19.506 eplased time 0.024\n",
      "[epoch 120, iter    30] loss: 22.602 eplased time 0.020\n",
      "[epoch 120, iter    40] loss: 22.638 eplased time 0.021\n",
      "[epoch 120, iter    50] loss: 19.682 eplased time 0.020\n",
      "[epoch 120, iter    60] loss: 22.563 eplased time 0.020\n",
      "[epoch 120, iter    70] loss: 21.368 eplased time 0.020\n",
      "[epoch 120, iter    80] loss: 18.925 eplased time 0.022\n",
      "[epoch 121, iter    10] loss: 20.167 eplased time 0.021\n",
      "[epoch 121, iter    20] loss: 23.743 eplased time 0.025\n",
      "[epoch 121, iter    30] loss: 20.900 eplased time 0.026\n",
      "[epoch 121, iter    40] loss: 23.583 eplased time 0.025\n",
      "[epoch 121, iter    50] loss: 22.135 eplased time 0.023\n",
      "[epoch 121, iter    60] loss: 20.408 eplased time 0.021\n",
      "[epoch 121, iter    70] loss: 19.900 eplased time 0.020\n",
      "[epoch 121, iter    80] loss: 20.196 eplased time 0.021\n",
      "[epoch 122, iter    10] loss: 19.963 eplased time 0.021\n",
      "[epoch 122, iter    20] loss: 22.199 eplased time 0.020\n",
      "[epoch 122, iter    30] loss: 21.961 eplased time 0.024\n",
      "[epoch 122, iter    40] loss: 20.202 eplased time 0.023\n",
      "[epoch 122, iter    50] loss: 18.735 eplased time 0.022\n",
      "[epoch 122, iter    60] loss: 20.256 eplased time 0.020\n",
      "[epoch 122, iter    70] loss: 23.921 eplased time 0.020\n",
      "[epoch 122, iter    80] loss: 23.288 eplased time 0.021\n",
      "[epoch 123, iter    10] loss: 22.502 eplased time 0.021\n",
      "[epoch 123, iter    20] loss: 21.313 eplased time 0.021\n",
      "[epoch 123, iter    30] loss: 19.672 eplased time 0.021\n",
      "[epoch 123, iter    40] loss: 22.594 eplased time 0.020\n",
      "[epoch 123, iter    50] loss: 21.584 eplased time 0.023\n",
      "[epoch 123, iter    60] loss: 21.951 eplased time 0.022\n",
      "[epoch 123, iter    70] loss: 18.606 eplased time 0.023\n",
      "[epoch 123, iter    80] loss: 22.600 eplased time 0.021\n",
      "[epoch 124, iter    10] loss: 23.234 eplased time 0.020\n",
      "[epoch 124, iter    20] loss: 22.744 eplased time 0.021\n",
      "[epoch 124, iter    30] loss: 19.627 eplased time 0.021\n",
      "[epoch 124, iter    40] loss: 22.876 eplased time 0.021\n",
      "[epoch 124, iter    50] loss: 23.260 eplased time 0.020\n",
      "[epoch 124, iter    60] loss: 19.534 eplased time 0.019\n",
      "[epoch 124, iter    70] loss: 20.984 eplased time 0.022\n",
      "[epoch 124, iter    80] loss: 18.560 eplased time 0.021\n",
      "[epoch 125, iter    10] loss: 21.184 eplased time 0.022\n",
      "[epoch 125, iter    20] loss: 22.791 eplased time 0.019\n",
      "[epoch 125, iter    30] loss: 19.079 eplased time 0.019\n",
      "[epoch 125, iter    40] loss: 21.322 eplased time 0.020\n",
      "[epoch 125, iter    50] loss: 21.660 eplased time 0.020\n",
      "[epoch 125, iter    60] loss: 21.801 eplased time 0.020\n",
      "[epoch 125, iter    70] loss: 21.285 eplased time 0.021\n",
      "[epoch 125, iter    80] loss: 20.461 eplased time 0.019\n",
      "[epoch 126, iter    10] loss: 21.528 eplased time 0.021\n",
      "[epoch 126, iter    20] loss: 20.970 eplased time 0.023\n",
      "[epoch 126, iter    30] loss: 15.324 eplased time 0.022\n",
      "[epoch 126, iter    40] loss: 22.154 eplased time 0.023\n",
      "[epoch 126, iter    50] loss: 20.793 eplased time 0.019\n",
      "[epoch 126, iter    60] loss: 21.729 eplased time 0.019\n",
      "[epoch 126, iter    70] loss: 22.232 eplased time 0.020\n",
      "[epoch 126, iter    80] loss: 24.808 eplased time 0.020\n",
      "[epoch 127, iter    10] loss: 19.868 eplased time 0.019\n",
      "[epoch 127, iter    20] loss: 21.140 eplased time 0.020\n",
      "[epoch 127, iter    30] loss: 22.566 eplased time 0.021\n",
      "[epoch 127, iter    40] loss: 20.516 eplased time 0.021\n",
      "[epoch 127, iter    50] loss: 20.652 eplased time 0.023\n",
      "[epoch 127, iter    60] loss: 22.049 eplased time 0.019\n",
      "[epoch 127, iter    70] loss: 21.198 eplased time 0.019\n",
      "[epoch 127, iter    80] loss: 20.851 eplased time 0.019\n",
      "[epoch 128, iter    10] loss: 21.940 eplased time 0.019\n",
      "[epoch 128, iter    20] loss: 19.815 eplased time 0.019\n",
      "[epoch 128, iter    30] loss: 21.446 eplased time 0.018\n",
      "[epoch 128, iter    40] loss: 23.184 eplased time 0.019\n",
      "[epoch 128, iter    50] loss: 19.434 eplased time 0.019\n",
      "[epoch 128, iter    60] loss: 19.107 eplased time 0.022\n",
      "[epoch 128, iter    70] loss: 21.547 eplased time 0.021\n",
      "[epoch 128, iter    80] loss: 21.406 eplased time 0.020\n",
      "[epoch 129, iter    10] loss: 21.464 eplased time 0.019\n",
      "[epoch 129, iter    20] loss: 22.740 eplased time 0.019\n",
      "[epoch 129, iter    30] loss: 21.300 eplased time 0.022\n",
      "[epoch 129, iter    40] loss: 17.171 eplased time 0.019\n",
      "[epoch 129, iter    50] loss: 19.730 eplased time 0.019\n",
      "[epoch 129, iter    60] loss: 18.696 eplased time 0.019\n",
      "[epoch 129, iter    70] loss: 24.320 eplased time 0.019\n",
      "[epoch 129, iter    80] loss: 20.609 eplased time 0.019\n",
      "[epoch 130, iter    10] loss: 20.989 eplased time 0.023\n",
      "[epoch 130, iter    20] loss: 17.454 eplased time 0.022\n",
      "[epoch 130, iter    30] loss: 21.547 eplased time 0.019\n",
      "[epoch 130, iter    40] loss: 20.764 eplased time 0.019\n",
      "[epoch 130, iter    50] loss: 21.331 eplased time 0.019\n",
      "[epoch 130, iter    60] loss: 23.174 eplased time 0.019\n",
      "[epoch 130, iter    70] loss: 18.898 eplased time 0.019\n",
      "[epoch 130, iter    80] loss: 20.619 eplased time 0.019\n",
      "[epoch 131, iter    10] loss: 22.025 eplased time 0.019\n",
      "[epoch 131, iter    20] loss: 21.868 eplased time 0.019\n",
      "[epoch 131, iter    30] loss: 23.021 eplased time 0.021\n",
      "[epoch 131, iter    40] loss: 18.130 eplased time 0.027\n",
      "[epoch 131, iter    50] loss: 20.305 eplased time 0.022\n",
      "[epoch 131, iter    60] loss: 18.797 eplased time 0.020\n",
      "[epoch 131, iter    70] loss: 20.980 eplased time 0.020\n",
      "[epoch 131, iter    80] loss: 21.489 eplased time 0.020\n",
      "[epoch 132, iter    10] loss: 19.781 eplased time 0.020\n",
      "[epoch 132, iter    20] loss: 22.725 eplased time 0.019\n",
      "[epoch 132, iter    30] loss: 23.607 eplased time 0.019\n",
      "[epoch 132, iter    40] loss: 19.911 eplased time 0.019\n",
      "[epoch 132, iter    50] loss: 17.542 eplased time 0.019\n",
      "[epoch 132, iter    60] loss: 18.200 eplased time 0.019\n",
      "[epoch 132, iter    70] loss: 19.210 eplased time 0.022\n",
      "[epoch 132, iter    80] loss: 23.180 eplased time 0.022\n",
      "[epoch 133, iter    10] loss: 22.243 eplased time 0.022\n",
      "[epoch 133, iter    20] loss: 21.358 eplased time 0.019\n",
      "[epoch 133, iter    30] loss: 19.860 eplased time 0.019\n",
      "[epoch 133, iter    40] loss: 20.818 eplased time 0.019\n",
      "[epoch 133, iter    50] loss: 20.181 eplased time 0.022\n",
      "[epoch 133, iter    60] loss: 21.773 eplased time 0.019\n",
      "[epoch 133, iter    70] loss: 16.825 eplased time 0.019\n",
      "[epoch 133, iter    80] loss: 20.856 eplased time 0.019\n",
      "[epoch 134, iter    10] loss: 19.857 eplased time 0.020\n",
      "[epoch 134, iter    20] loss: 21.932 eplased time 0.023\n",
      "[epoch 134, iter    30] loss: 22.018 eplased time 0.023\n",
      "[epoch 134, iter    40] loss: 18.282 eplased time 0.020\n",
      "[epoch 134, iter    50] loss: 20.783 eplased time 0.019\n",
      "[epoch 134, iter    60] loss: 21.816 eplased time 0.020\n",
      "[epoch 134, iter    70] loss: 20.090 eplased time 0.020\n",
      "[epoch 134, iter    80] loss: 19.846 eplased time 0.022\n",
      "[epoch 135, iter    10] loss: 21.253 eplased time 0.021\n",
      "[epoch 135, iter    20] loss: 18.334 eplased time 0.023\n",
      "[epoch 135, iter    30] loss: 21.070 eplased time 0.026\n",
      "[epoch 135, iter    40] loss: 18.476 eplased time 0.026\n",
      "[epoch 135, iter    50] loss: 22.565 eplased time 0.025\n",
      "[epoch 135, iter    60] loss: 19.546 eplased time 0.024\n",
      "[epoch 135, iter    70] loss: 20.931 eplased time 0.024\n",
      "[epoch 135, iter    80] loss: 21.291 eplased time 0.021\n",
      "[epoch 136, iter    10] loss: 19.873 eplased time 0.019\n",
      "[epoch 136, iter    20] loss: 19.142 eplased time 0.019\n",
      "[epoch 136, iter    30] loss: 22.943 eplased time 0.020\n",
      "[epoch 136, iter    40] loss: 19.197 eplased time 0.022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 136, iter    50] loss: 19.084 eplased time 0.022\n",
      "[epoch 136, iter    60] loss: 21.991 eplased time 0.022\n",
      "[epoch 136, iter    70] loss: 20.671 eplased time 0.021\n",
      "[epoch 136, iter    80] loss: 20.149 eplased time 0.019\n",
      "[epoch 137, iter    10] loss: 17.911 eplased time 0.019\n",
      "[epoch 137, iter    20] loss: 19.920 eplased time 0.019\n",
      "[epoch 137, iter    30] loss: 20.981 eplased time 0.019\n",
      "[epoch 137, iter    40] loss: 23.698 eplased time 0.019\n",
      "[epoch 137, iter    50] loss: 20.398 eplased time 0.019\n",
      "[epoch 137, iter    60] loss: 18.568 eplased time 0.019\n",
      "[epoch 137, iter    70] loss: 21.757 eplased time 0.021\n",
      "[epoch 137, iter    80] loss: 19.910 eplased time 0.023\n",
      "[epoch 138, iter    10] loss: 19.034 eplased time 0.025\n",
      "[epoch 138, iter    20] loss: 21.633 eplased time 0.022\n",
      "[epoch 138, iter    30] loss: 17.011 eplased time 0.020\n",
      "[epoch 138, iter    40] loss: 20.482 eplased time 0.021\n",
      "[epoch 138, iter    50] loss: 20.937 eplased time 0.020\n",
      "[epoch 138, iter    60] loss: 19.872 eplased time 0.020\n",
      "[epoch 138, iter    70] loss: 20.791 eplased time 0.020\n",
      "[epoch 138, iter    80] loss: 22.584 eplased time 0.021\n",
      "[epoch 139, iter    10] loss: 20.024 eplased time 0.020\n",
      "[epoch 139, iter    20] loss: 18.927 eplased time 0.023\n",
      "[epoch 139, iter    30] loss: 22.034 eplased time 0.023\n",
      "[epoch 139, iter    40] loss: 19.152 eplased time 0.023\n",
      "[epoch 139, iter    50] loss: 22.296 eplased time 0.025\n",
      "[epoch 139, iter    60] loss: 19.927 eplased time 0.023\n",
      "[epoch 139, iter    70] loss: 20.017 eplased time 0.021\n",
      "[epoch 139, iter    80] loss: 20.603 eplased time 0.024\n",
      "[epoch 140, iter    10] loss: 18.979 eplased time 0.023\n",
      "[epoch 140, iter    20] loss: 22.242 eplased time 0.020\n",
      "[epoch 140, iter    30] loss: 16.504 eplased time 0.021\n",
      "[epoch 140, iter    40] loss: 19.783 eplased time 0.023\n",
      "[epoch 140, iter    50] loss: 22.453 eplased time 0.024\n",
      "[epoch 140, iter    60] loss: 21.007 eplased time 0.020\n",
      "[epoch 140, iter    70] loss: 19.300 eplased time 0.019\n",
      "[epoch 140, iter    80] loss: 20.633 eplased time 0.019\n",
      "[epoch 141, iter    10] loss: 22.019 eplased time 0.020\n",
      "[epoch 141, iter    20] loss: 19.517 eplased time 0.020\n",
      "[epoch 141, iter    30] loss: 18.646 eplased time 0.020\n",
      "[epoch 141, iter    40] loss: 20.573 eplased time 0.020\n",
      "[epoch 141, iter    50] loss: 19.736 eplased time 0.022\n",
      "[epoch 141, iter    60] loss: 20.829 eplased time 0.022\n",
      "[epoch 141, iter    70] loss: 21.036 eplased time 0.022\n",
      "[epoch 141, iter    80] loss: 20.353 eplased time 0.021\n",
      "[epoch 142, iter    10] loss: 20.940 eplased time 0.019\n",
      "[epoch 142, iter    20] loss: 19.531 eplased time 0.021\n",
      "[epoch 142, iter    30] loss: 19.370 eplased time 0.022\n",
      "[epoch 142, iter    40] loss: 19.328 eplased time 0.022\n",
      "[epoch 142, iter    50] loss: 18.514 eplased time 0.020\n",
      "[epoch 142, iter    60] loss: 23.480 eplased time 0.020\n",
      "[epoch 142, iter    70] loss: 20.452 eplased time 0.022\n",
      "[epoch 142, iter    80] loss: 19.604 eplased time 0.022\n",
      "[epoch 143, iter    10] loss: 20.752 eplased time 0.022\n",
      "[epoch 143, iter    20] loss: 20.944 eplased time 0.023\n",
      "[epoch 143, iter    30] loss: 18.937 eplased time 0.020\n",
      "[epoch 143, iter    40] loss: 20.212 eplased time 0.023\n",
      "[epoch 143, iter    50] loss: 19.449 eplased time 0.019\n",
      "[epoch 143, iter    60] loss: 22.156 eplased time 0.019\n",
      "[epoch 143, iter    70] loss: 19.527 eplased time 0.019\n",
      "[epoch 143, iter    80] loss: 19.721 eplased time 0.019\n",
      "[epoch 144, iter    10] loss: 17.938 eplased time 0.023\n",
      "[epoch 144, iter    20] loss: 19.387 eplased time 0.022\n",
      "[epoch 144, iter    30] loss: 18.593 eplased time 0.022\n",
      "[epoch 144, iter    40] loss: 19.294 eplased time 0.020\n",
      "[epoch 144, iter    50] loss: 20.389 eplased time 0.020\n",
      "[epoch 144, iter    60] loss: 21.354 eplased time 0.020\n",
      "[epoch 144, iter    70] loss: 22.778 eplased time 0.021\n",
      "[epoch 144, iter    80] loss: 21.020 eplased time 0.020\n",
      "[epoch 145, iter    10] loss: 21.355 eplased time 0.019\n",
      "[epoch 145, iter    20] loss: 19.482 eplased time 0.019\n",
      "[epoch 145, iter    30] loss: 20.183 eplased time 0.024\n",
      "[epoch 145, iter    40] loss: 19.336 eplased time 0.023\n",
      "[epoch 145, iter    50] loss: 21.599 eplased time 0.021\n",
      "[epoch 145, iter    60] loss: 19.972 eplased time 0.020\n",
      "[epoch 145, iter    70] loss: 20.737 eplased time 0.020\n",
      "[epoch 145, iter    80] loss: 18.159 eplased time 0.020\n",
      "[epoch 146, iter    10] loss: 21.543 eplased time 0.022\n",
      "[epoch 146, iter    20] loss: 20.938 eplased time 0.020\n",
      "[epoch 146, iter    30] loss: 16.659 eplased time 0.019\n",
      "[epoch 146, iter    40] loss: 18.429 eplased time 0.019\n",
      "[epoch 146, iter    50] loss: 21.042 eplased time 0.020\n",
      "[epoch 146, iter    60] loss: 18.152 eplased time 0.024\n",
      "[epoch 146, iter    70] loss: 19.769 eplased time 0.024\n",
      "[epoch 146, iter    80] loss: 22.611 eplased time 0.020\n",
      "[epoch 147, iter    10] loss: 18.612 eplased time 0.019\n",
      "[epoch 147, iter    20] loss: 17.191 eplased time 0.019\n",
      "[epoch 147, iter    30] loss: 20.782 eplased time 0.020\n",
      "[epoch 147, iter    40] loss: 23.111 eplased time 0.019\n",
      "[epoch 147, iter    50] loss: 19.603 eplased time 0.019\n",
      "[epoch 147, iter    60] loss: 19.921 eplased time 0.019\n",
      "[epoch 147, iter    70] loss: 20.003 eplased time 0.020\n",
      "[epoch 147, iter    80] loss: 20.754 eplased time 0.022\n",
      "[epoch 148, iter    10] loss: 19.348 eplased time 0.020\n",
      "[epoch 148, iter    20] loss: 15.028 eplased time 0.021\n",
      "[epoch 148, iter    30] loss: 20.863 eplased time 0.020\n",
      "[epoch 148, iter    40] loss: 20.586 eplased time 0.020\n",
      "[epoch 148, iter    50] loss: 20.749 eplased time 0.020\n",
      "[epoch 148, iter    60] loss: 20.344 eplased time 0.020\n",
      "[epoch 148, iter    70] loss: 20.379 eplased time 0.020\n",
      "[epoch 148, iter    80] loss: 21.900 eplased time 0.019\n",
      "[epoch 149, iter    10] loss: 21.851 eplased time 0.021\n",
      "[epoch 149, iter    20] loss: 20.248 eplased time 0.025\n",
      "[epoch 149, iter    30] loss: 16.619 eplased time 0.022\n",
      "[epoch 149, iter    40] loss: 17.996 eplased time 0.020\n",
      "[epoch 149, iter    50] loss: 21.117 eplased time 0.020\n",
      "[epoch 149, iter    60] loss: 22.062 eplased time 0.021\n",
      "[epoch 149, iter    70] loss: 19.617 eplased time 0.020\n",
      "[epoch 149, iter    80] loss: 18.319 eplased time 0.021\n",
      "[epoch 150, iter    10] loss: 20.365 eplased time 0.020\n",
      "[epoch 150, iter    20] loss: 20.086 eplased time 0.020\n",
      "[epoch 150, iter    30] loss: 20.913 eplased time 0.022\n",
      "[epoch 150, iter    40] loss: 18.288 eplased time 0.022\n",
      "[epoch 150, iter    50] loss: 20.610 eplased time 0.024\n",
      "[epoch 150, iter    60] loss: 21.037 eplased time 0.020\n",
      "[epoch 150, iter    70] loss: 17.149 eplased time 0.020\n",
      "[epoch 150, iter    80] loss: 20.590 eplased time 0.020\n",
      "[epoch 151, iter    10] loss: 18.112 eplased time 0.022\n",
      "[epoch 151, iter    20] loss: 19.051 eplased time 0.021\n",
      "[epoch 151, iter    30] loss: 20.147 eplased time 0.020\n",
      "[epoch 151, iter    40] loss: 19.059 eplased time 0.020\n",
      "[epoch 151, iter    50] loss: 21.660 eplased time 0.023\n",
      "[epoch 151, iter    60] loss: 19.510 eplased time 0.022\n",
      "[epoch 151, iter    70] loss: 21.019 eplased time 0.021\n",
      "[epoch 151, iter    80] loss: 20.940 eplased time 0.021\n",
      "[epoch 152, iter    10] loss: 20.339 eplased time 0.019\n",
      "[epoch 152, iter    20] loss: 20.666 eplased time 0.020\n",
      "[epoch 152, iter    30] loss: 20.601 eplased time 0.023\n",
      "[epoch 152, iter    40] loss: 21.125 eplased time 0.020\n",
      "[epoch 152, iter    50] loss: 16.448 eplased time 0.023\n",
      "[epoch 152, iter    60] loss: 17.262 eplased time 0.019\n",
      "[epoch 152, iter    70] loss: 21.766 eplased time 0.022\n",
      "[epoch 152, iter    80] loss: 18.974 eplased time 0.022\n",
      "[epoch 153, iter    10] loss: 18.730 eplased time 0.021\n",
      "[epoch 153, iter    20] loss: 19.179 eplased time 0.019\n",
      "[epoch 153, iter    30] loss: 17.167 eplased time 0.020\n",
      "[epoch 153, iter    40] loss: 22.184 eplased time 0.020\n",
      "[epoch 153, iter    50] loss: 18.951 eplased time 0.020\n",
      "[epoch 153, iter    60] loss: 21.144 eplased time 0.023\n",
      "[epoch 153, iter    70] loss: 20.164 eplased time 0.020\n",
      "[epoch 153, iter    80] loss: 20.433 eplased time 0.019\n",
      "[epoch 154, iter    10] loss: 19.721 eplased time 0.020\n",
      "[epoch 154, iter    20] loss: 20.156 eplased time 0.024\n",
      "[epoch 154, iter    30] loss: 21.521 eplased time 0.020\n",
      "[epoch 154, iter    40] loss: 18.361 eplased time 0.020\n",
      "[epoch 154, iter    50] loss: 20.640 eplased time 0.020\n",
      "[epoch 154, iter    60] loss: 20.449 eplased time 0.020\n",
      "[epoch 154, iter    70] loss: 18.400 eplased time 0.020\n",
      "[epoch 154, iter    80] loss: 18.626 eplased time 0.020\n",
      "[epoch 155, iter    10] loss: 18.708 eplased time 0.020\n",
      "[epoch 155, iter    20] loss: 21.173 eplased time 0.020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 155, iter    30] loss: 21.361 eplased time 0.021\n",
      "[epoch 155, iter    40] loss: 20.087 eplased time 0.024\n",
      "[epoch 155, iter    50] loss: 19.591 eplased time 0.021\n",
      "[epoch 155, iter    60] loss: 17.839 eplased time 0.019\n",
      "[epoch 155, iter    70] loss: 21.121 eplased time 0.019\n",
      "[epoch 155, iter    80] loss: 18.264 eplased time 0.021\n",
      "[epoch 156, iter    10] loss: 21.077 eplased time 0.020\n",
      "[epoch 156, iter    20] loss: 18.356 eplased time 0.020\n",
      "[epoch 156, iter    30] loss: 19.827 eplased time 0.020\n",
      "[epoch 156, iter    40] loss: 21.175 eplased time 0.020\n",
      "[epoch 156, iter    50] loss: 19.181 eplased time 0.022\n",
      "[epoch 156, iter    60] loss: 18.459 eplased time 0.023\n",
      "[epoch 156, iter    70] loss: 22.106 eplased time 0.023\n",
      "[epoch 156, iter    80] loss: 17.470 eplased time 0.019\n",
      "[epoch 157, iter    10] loss: 21.525 eplased time 0.019\n",
      "[epoch 157, iter    20] loss: 16.184 eplased time 0.020\n",
      "[epoch 157, iter    30] loss: 19.255 eplased time 0.023\n",
      "[epoch 157, iter    40] loss: 20.474 eplased time 0.020\n",
      "[epoch 157, iter    50] loss: 21.153 eplased time 0.020\n",
      "[epoch 157, iter    60] loss: 20.028 eplased time 0.020\n",
      "[epoch 157, iter    70] loss: 18.730 eplased time 0.023\n",
      "[epoch 157, iter    80] loss: 19.770 eplased time 0.022\n",
      "[epoch 158, iter    10] loss: 18.560 eplased time 0.025\n",
      "[epoch 158, iter    20] loss: 18.243 eplased time 0.023\n",
      "[epoch 158, iter    30] loss: 19.700 eplased time 0.020\n",
      "[epoch 158, iter    40] loss: 21.793 eplased time 0.022\n",
      "[epoch 158, iter    50] loss: 18.496 eplased time 0.020\n",
      "[epoch 158, iter    60] loss: 22.040 eplased time 0.020\n",
      "[epoch 158, iter    70] loss: 20.345 eplased time 0.020\n",
      "[epoch 158, iter    80] loss: 18.046 eplased time 0.020\n",
      "[epoch 159, iter    10] loss: 18.839 eplased time 0.025\n",
      "[epoch 159, iter    20] loss: 19.464 eplased time 0.024\n",
      "[epoch 159, iter    30] loss: 19.597 eplased time 0.020\n",
      "[epoch 159, iter    40] loss: 19.158 eplased time 0.022\n",
      "[epoch 159, iter    50] loss: 20.070 eplased time 0.020\n",
      "[epoch 159, iter    60] loss: 19.254 eplased time 0.020\n",
      "[epoch 159, iter    70] loss: 21.401 eplased time 0.020\n",
      "[epoch 159, iter    80] loss: 18.475 eplased time 0.020\n",
      "[epoch 160, iter    10] loss: 18.264 eplased time 0.020\n",
      "[epoch 160, iter    20] loss: 19.114 eplased time 0.020\n",
      "[epoch 160, iter    30] loss: 18.687 eplased time 0.022\n",
      "[epoch 160, iter    40] loss: 18.791 eplased time 0.023\n",
      "[epoch 160, iter    50] loss: 17.608 eplased time 0.023\n",
      "[epoch 160, iter    60] loss: 20.987 eplased time 0.020\n",
      "[epoch 160, iter    70] loss: 19.619 eplased time 0.019\n",
      "[epoch 160, iter    80] loss: 22.764 eplased time 0.020\n",
      "[epoch 161, iter    10] loss: 19.036 eplased time 0.021\n",
      "[epoch 161, iter    20] loss: 19.707 eplased time 0.020\n",
      "[epoch 161, iter    30] loss: 17.583 eplased time 0.020\n",
      "[epoch 161, iter    40] loss: 20.297 eplased time 0.020\n",
      "[epoch 161, iter    50] loss: 21.067 eplased time 0.023\n",
      "[epoch 161, iter    60] loss: 22.435 eplased time 0.021\n",
      "[epoch 161, iter    70] loss: 17.435 eplased time 0.021\n",
      "[epoch 161, iter    80] loss: 18.995 eplased time 0.019\n",
      "[epoch 162, iter    10] loss: 21.722 eplased time 0.019\n",
      "[epoch 162, iter    20] loss: 19.865 eplased time 0.021\n",
      "[epoch 162, iter    30] loss: 20.208 eplased time 0.020\n",
      "[epoch 162, iter    40] loss: 18.667 eplased time 0.020\n",
      "[epoch 162, iter    50] loss: 16.960 eplased time 0.020\n",
      "[epoch 162, iter    60] loss: 17.508 eplased time 0.020\n",
      "[epoch 162, iter    70] loss: 20.771 eplased time 0.021\n",
      "[epoch 162, iter    80] loss: 21.521 eplased time 0.023\n",
      "[epoch 163, iter    10] loss: 15.449 eplased time 0.021\n",
      "[epoch 163, iter    20] loss: 20.427 eplased time 0.020\n",
      "[epoch 163, iter    30] loss: 19.522 eplased time 0.020\n",
      "[epoch 163, iter    40] loss: 20.610 eplased time 0.019\n",
      "[epoch 163, iter    50] loss: 20.700 eplased time 0.020\n",
      "[epoch 163, iter    60] loss: 18.925 eplased time 0.020\n",
      "[epoch 163, iter    70] loss: 20.528 eplased time 0.020\n",
      "[epoch 163, iter    80] loss: 19.505 eplased time 0.020\n",
      "[epoch 164, iter    10] loss: 19.522 eplased time 0.021\n",
      "[epoch 164, iter    20] loss: 21.097 eplased time 0.026\n",
      "[epoch 164, iter    30] loss: 22.848 eplased time 0.021\n",
      "[epoch 164, iter    40] loss: 16.079 eplased time 0.020\n",
      "[epoch 164, iter    50] loss: 19.937 eplased time 0.020\n",
      "[epoch 164, iter    60] loss: 17.862 eplased time 0.020\n",
      "[epoch 164, iter    70] loss: 17.630 eplased time 0.020\n",
      "[epoch 164, iter    80] loss: 20.172 eplased time 0.020\n",
      "[epoch 165, iter    10] loss: 19.881 eplased time 0.020\n",
      "[epoch 165, iter    20] loss: 21.396 eplased time 0.023\n",
      "[epoch 165, iter    30] loss: 18.977 eplased time 0.022\n",
      "[epoch 165, iter    40] loss: 20.857 eplased time 0.022\n",
      "[epoch 165, iter    50] loss: 17.684 eplased time 0.024\n",
      "[epoch 165, iter    60] loss: 16.912 eplased time 0.020\n",
      "[epoch 165, iter    70] loss: 20.958 eplased time 0.020\n",
      "[epoch 165, iter    80] loss: 19.906 eplased time 0.020\n",
      "[epoch 166, iter    10] loss: 16.161 eplased time 0.020\n",
      "[epoch 166, iter    20] loss: 20.087 eplased time 0.020\n",
      "[epoch 166, iter    30] loss: 19.711 eplased time 0.020\n",
      "[epoch 166, iter    40] loss: 19.830 eplased time 0.022\n",
      "[epoch 166, iter    50] loss: 20.628 eplased time 0.024\n",
      "[epoch 166, iter    60] loss: 19.903 eplased time 0.022\n",
      "[epoch 166, iter    70] loss: 19.027 eplased time 0.024\n",
      "[epoch 166, iter    80] loss: 20.378 eplased time 0.020\n",
      "[epoch 167, iter    10] loss: 18.793 eplased time 0.020\n",
      "[epoch 167, iter    20] loss: 18.672 eplased time 0.020\n",
      "[epoch 167, iter    30] loss: 18.059 eplased time 0.020\n",
      "[epoch 167, iter    40] loss: 20.086 eplased time 0.020\n",
      "[epoch 167, iter    50] loss: 18.522 eplased time 0.019\n",
      "[epoch 167, iter    60] loss: 23.556 eplased time 0.019\n",
      "[epoch 167, iter    70] loss: 19.437 eplased time 0.023\n",
      "[epoch 167, iter    80] loss: 19.028 eplased time 0.023\n",
      "[epoch 168, iter    10] loss: 20.648 eplased time 0.023\n",
      "[epoch 168, iter    20] loss: 22.644 eplased time 0.020\n",
      "[epoch 168, iter    30] loss: 17.999 eplased time 0.020\n",
      "[epoch 168, iter    40] loss: 18.075 eplased time 0.020\n",
      "[epoch 168, iter    50] loss: 19.564 eplased time 0.020\n",
      "[epoch 168, iter    60] loss: 18.868 eplased time 0.020\n",
      "[epoch 168, iter    70] loss: 20.156 eplased time 0.023\n",
      "[epoch 168, iter    80] loss: 18.437 eplased time 0.021\n",
      "[epoch 169, iter    10] loss: 20.637 eplased time 0.026\n",
      "[epoch 169, iter    20] loss: 20.953 eplased time 0.026\n",
      "[epoch 169, iter    30] loss: 18.427 eplased time 0.024\n",
      "[epoch 169, iter    40] loss: 17.838 eplased time 0.025\n",
      "[epoch 169, iter    50] loss: 18.382 eplased time 0.023\n",
      "[epoch 169, iter    60] loss: 19.589 eplased time 0.020\n",
      "[epoch 169, iter    70] loss: 18.654 eplased time 0.021\n",
      "[epoch 169, iter    80] loss: 20.037 eplased time 0.021\n",
      "[epoch 170, iter    10] loss: 21.395 eplased time 0.021\n",
      "[epoch 170, iter    20] loss: 21.627 eplased time 0.021\n",
      "[epoch 170, iter    30] loss: 19.142 eplased time 0.023\n",
      "[epoch 170, iter    40] loss: 14.984 eplased time 0.024\n",
      "[epoch 170, iter    50] loss: 19.145 eplased time 0.021\n",
      "[epoch 170, iter    60] loss: 21.766 eplased time 0.020\n",
      "[epoch 170, iter    70] loss: 20.459 eplased time 0.020\n",
      "[epoch 170, iter    80] loss: 17.478 eplased time 0.021\n",
      "[epoch 171, iter    10] loss: 21.102 eplased time 0.020\n",
      "[epoch 171, iter    20] loss: 18.997 eplased time 0.020\n",
      "[epoch 171, iter    30] loss: 21.644 eplased time 0.020\n",
      "[epoch 171, iter    40] loss: 17.946 eplased time 0.023\n",
      "[epoch 171, iter    50] loss: 18.937 eplased time 0.022\n",
      "[epoch 171, iter    60] loss: 18.720 eplased time 0.022\n",
      "[epoch 171, iter    70] loss: 18.957 eplased time 0.021\n",
      "[epoch 171, iter    80] loss: 18.941 eplased time 0.020\n",
      "[epoch 172, iter    10] loss: 20.179 eplased time 0.020\n",
      "[epoch 172, iter    20] loss: 20.197 eplased time 0.026\n",
      "[epoch 172, iter    30] loss: 20.617 eplased time 0.021\n",
      "[epoch 172, iter    40] loss: 20.478 eplased time 0.019\n",
      "[epoch 172, iter    50] loss: 17.667 eplased time 0.019\n",
      "[epoch 172, iter    60] loss: 20.570 eplased time 0.023\n",
      "[epoch 172, iter    70] loss: 19.654 eplased time 0.022\n",
      "[epoch 172, iter    80] loss: 15.663 eplased time 0.024\n",
      "[epoch 173, iter    10] loss: 20.631 eplased time 0.025\n",
      "[epoch 173, iter    20] loss: 18.747 eplased time 0.021\n",
      "[epoch 173, iter    30] loss: 17.420 eplased time 0.020\n",
      "[epoch 173, iter    40] loss: 20.418 eplased time 0.020\n",
      "[epoch 173, iter    50] loss: 18.982 eplased time 0.023\n",
      "[epoch 173, iter    60] loss: 19.446 eplased time 0.021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 173, iter    70] loss: 19.362 eplased time 0.021\n",
      "[epoch 173, iter    80] loss: 20.493 eplased time 0.022\n",
      "[epoch 174, iter    10] loss: 21.249 eplased time 0.022\n",
      "[epoch 174, iter    20] loss: 20.483 eplased time 0.021\n",
      "[epoch 174, iter    30] loss: 19.238 eplased time 0.021\n",
      "[epoch 174, iter    40] loss: 17.385 eplased time 0.021\n",
      "[epoch 174, iter    50] loss: 19.304 eplased time 0.021\n",
      "[epoch 174, iter    60] loss: 18.908 eplased time 0.021\n",
      "[epoch 174, iter    70] loss: 21.538 eplased time 0.020\n",
      "[epoch 174, iter    80] loss: 16.594 eplased time 0.020\n",
      "[epoch 175, iter    10] loss: 21.141 eplased time 0.024\n",
      "[epoch 175, iter    20] loss: 18.999 eplased time 0.023\n",
      "[epoch 175, iter    30] loss: 19.523 eplased time 0.022\n",
      "[epoch 175, iter    40] loss: 19.267 eplased time 0.020\n",
      "[epoch 175, iter    50] loss: 16.769 eplased time 0.020\n",
      "[epoch 175, iter    60] loss: 19.795 eplased time 0.020\n",
      "[epoch 175, iter    70] loss: 18.595 eplased time 0.020\n",
      "[epoch 175, iter    80] loss: 20.136 eplased time 0.023\n",
      "[epoch 176, iter    10] loss: 22.470 eplased time 0.020\n",
      "[epoch 176, iter    20] loss: 16.860 eplased time 0.020\n",
      "[epoch 176, iter    30] loss: 19.873 eplased time 0.026\n",
      "[epoch 176, iter    40] loss: 18.884 eplased time 0.023\n",
      "[epoch 176, iter    50] loss: 19.408 eplased time 0.025\n",
      "[epoch 176, iter    60] loss: 18.350 eplased time 0.020\n",
      "[epoch 176, iter    70] loss: 18.784 eplased time 0.021\n",
      "[epoch 176, iter    80] loss: 20.260 eplased time 0.020\n",
      "[epoch 177, iter    10] loss: 19.991 eplased time 0.020\n",
      "[epoch 177, iter    20] loss: 19.537 eplased time 0.021\n",
      "[epoch 177, iter    30] loss: 19.324 eplased time 0.022\n",
      "[epoch 177, iter    40] loss: 16.202 eplased time 0.023\n",
      "[epoch 177, iter    50] loss: 21.342 eplased time 0.027\n",
      "[epoch 177, iter    60] loss: 17.215 eplased time 0.025\n",
      "[epoch 177, iter    70] loss: 19.651 eplased time 0.021\n",
      "[epoch 177, iter    80] loss: 22.181 eplased time 0.024\n",
      "[epoch 178, iter    10] loss: 19.338 eplased time 0.021\n",
      "[epoch 178, iter    20] loss: 18.579 eplased time 0.021\n",
      "[epoch 178, iter    30] loss: 21.430 eplased time 0.021\n",
      "[epoch 178, iter    40] loss: 18.979 eplased time 0.020\n",
      "[epoch 178, iter    50] loss: 19.522 eplased time 0.020\n",
      "[epoch 178, iter    60] loss: 18.932 eplased time 0.020\n",
      "[epoch 178, iter    70] loss: 19.393 eplased time 0.023\n",
      "[epoch 178, iter    80] loss: 19.478 eplased time 0.022\n",
      "[epoch 179, iter    10] loss: 20.272 eplased time 0.024\n",
      "[epoch 179, iter    20] loss: 18.035 eplased time 0.021\n",
      "[epoch 179, iter    30] loss: 18.442 eplased time 0.020\n",
      "[epoch 179, iter    40] loss: 19.850 eplased time 0.024\n",
      "[epoch 179, iter    50] loss: 16.826 eplased time 0.020\n",
      "[epoch 179, iter    60] loss: 18.488 eplased time 0.020\n",
      "[epoch 179, iter    70] loss: 21.513 eplased time 0.020\n",
      "[epoch 179, iter    80] loss: 20.601 eplased time 0.020\n",
      "[epoch 180, iter    10] loss: 19.406 eplased time 0.024\n",
      "[epoch 180, iter    20] loss: 17.634 eplased time 0.022\n",
      "[epoch 180, iter    30] loss: 18.700 eplased time 0.024\n",
      "[epoch 180, iter    40] loss: 17.891 eplased time 0.020\n",
      "[epoch 180, iter    50] loss: 19.261 eplased time 0.023\n",
      "[epoch 180, iter    60] loss: 20.487 eplased time 0.020\n",
      "[epoch 180, iter    70] loss: 20.648 eplased time 0.020\n",
      "[epoch 180, iter    80] loss: 21.307 eplased time 0.020\n",
      "[epoch 181, iter    10] loss: 22.487 eplased time 0.020\n",
      "[epoch 181, iter    20] loss: 20.213 eplased time 0.024\n",
      "[epoch 181, iter    30] loss: 16.736 eplased time 0.025\n",
      "[epoch 181, iter    40] loss: 20.834 eplased time 0.022\n",
      "[epoch 181, iter    50] loss: 19.230 eplased time 0.021\n",
      "[epoch 181, iter    60] loss: 20.390 eplased time 0.020\n",
      "[epoch 181, iter    70] loss: 16.426 eplased time 0.020\n",
      "[epoch 181, iter    80] loss: 19.115 eplased time 0.020\n",
      "[epoch 182, iter    10] loss: 19.377 eplased time 0.020\n",
      "[epoch 182, iter    20] loss: 20.343 eplased time 0.020\n",
      "[epoch 182, iter    30] loss: 20.358 eplased time 0.020\n",
      "[epoch 182, iter    40] loss: 17.358 eplased time 0.020\n",
      "[epoch 182, iter    50] loss: 19.835 eplased time 0.021\n",
      "[epoch 182, iter    60] loss: 18.302 eplased time 0.024\n",
      "[epoch 182, iter    70] loss: 18.874 eplased time 0.024\n",
      "[epoch 182, iter    80] loss: 20.355 eplased time 0.024\n",
      "[epoch 183, iter    10] loss: 18.919 eplased time 0.024\n",
      "[epoch 183, iter    20] loss: 19.594 eplased time 0.023\n",
      "[epoch 183, iter    30] loss: 20.367 eplased time 0.020\n",
      "[epoch 183, iter    40] loss: 19.311 eplased time 0.020\n",
      "[epoch 183, iter    50] loss: 18.617 eplased time 0.020\n",
      "[epoch 183, iter    60] loss: 18.737 eplased time 0.022\n",
      "[epoch 183, iter    70] loss: 18.921 eplased time 0.024\n",
      "[epoch 183, iter    80] loss: 20.756 eplased time 0.023\n",
      "[epoch 184, iter    10] loss: 19.997 eplased time 0.020\n",
      "[epoch 184, iter    20] loss: 20.700 eplased time 0.021\n",
      "[epoch 184, iter    30] loss: 16.738 eplased time 0.020\n",
      "[epoch 184, iter    40] loss: 18.487 eplased time 0.020\n",
      "[epoch 184, iter    50] loss: 20.056 eplased time 0.020\n",
      "[epoch 184, iter    60] loss: 20.301 eplased time 0.020\n",
      "[epoch 184, iter    70] loss: 17.925 eplased time 0.020\n",
      "[epoch 184, iter    80] loss: 21.723 eplased time 0.026\n",
      "[epoch 185, iter    10] loss: 19.200 eplased time 0.022\n",
      "[epoch 185, iter    20] loss: 19.097 eplased time 0.021\n",
      "[epoch 185, iter    30] loss: 18.827 eplased time 0.020\n",
      "[epoch 185, iter    40] loss: 21.387 eplased time 0.020\n",
      "[epoch 185, iter    50] loss: 16.692 eplased time 0.020\n",
      "[epoch 185, iter    60] loss: 18.090 eplased time 0.020\n",
      "[epoch 185, iter    70] loss: 20.961 eplased time 0.020\n",
      "[epoch 185, iter    80] loss: 19.482 eplased time 0.020\n",
      "[epoch 186, iter    10] loss: 18.025 eplased time 0.020\n",
      "[epoch 186, iter    20] loss: 19.093 eplased time 0.024\n",
      "[epoch 186, iter    30] loss: 18.976 eplased time 0.022\n",
      "[epoch 186, iter    40] loss: 18.534 eplased time 0.024\n",
      "[epoch 186, iter    50] loss: 18.714 eplased time 0.020\n",
      "[epoch 186, iter    60] loss: 19.818 eplased time 0.022\n",
      "[epoch 186, iter    70] loss: 21.933 eplased time 0.020\n",
      "[epoch 186, iter    80] loss: 19.513 eplased time 0.020\n",
      "[epoch 187, iter    10] loss: 17.162 eplased time 0.020\n",
      "[epoch 187, iter    20] loss: 18.967 eplased time 0.020\n",
      "[epoch 187, iter    30] loss: 19.760 eplased time 0.020\n",
      "[epoch 187, iter    40] loss: 19.230 eplased time 0.024\n",
      "[epoch 187, iter    50] loss: 20.411 eplased time 0.023\n",
      "[epoch 187, iter    60] loss: 17.155 eplased time 0.023\n",
      "[epoch 187, iter    70] loss: 20.767 eplased time 0.020\n",
      "[epoch 187, iter    80] loss: 20.871 eplased time 0.020\n",
      "[epoch 188, iter    10] loss: 20.866 eplased time 0.020\n",
      "[epoch 188, iter    20] loss: 20.746 eplased time 0.020\n",
      "[epoch 188, iter    30] loss: 20.004 eplased time 0.020\n",
      "[epoch 188, iter    40] loss: 19.699 eplased time 0.020\n",
      "[epoch 188, iter    50] loss: 17.970 eplased time 0.020\n",
      "[epoch 188, iter    60] loss: 18.241 eplased time 0.023\n",
      "[epoch 188, iter    70] loss: 17.998 eplased time 0.023\n",
      "[epoch 188, iter    80] loss: 18.927 eplased time 0.022\n",
      "[epoch 189, iter    10] loss: 18.756 eplased time 0.020\n",
      "[epoch 189, iter    20] loss: 19.141 eplased time 0.021\n",
      "[epoch 189, iter    30] loss: 18.253 eplased time 0.022\n",
      "[epoch 189, iter    40] loss: 18.389 eplased time 0.021\n",
      "[epoch 189, iter    50] loss: 19.372 eplased time 0.021\n",
      "[epoch 189, iter    60] loss: 18.521 eplased time 0.020\n",
      "[epoch 189, iter    70] loss: 21.875 eplased time 0.020\n",
      "[epoch 189, iter    80] loss: 20.270 eplased time 0.024\n",
      "[epoch 190, iter    10] loss: 18.670 eplased time 0.022\n",
      "[epoch 190, iter    20] loss: 21.592 eplased time 0.021\n",
      "[epoch 190, iter    30] loss: 19.577 eplased time 0.020\n",
      "[epoch 190, iter    40] loss: 18.778 eplased time 0.021\n",
      "[epoch 190, iter    50] loss: 18.259 eplased time 0.021\n",
      "[epoch 190, iter    60] loss: 17.741 eplased time 0.022\n",
      "[epoch 190, iter    70] loss: 20.392 eplased time 0.022\n",
      "[epoch 190, iter    80] loss: 18.322 eplased time 0.020\n",
      "[epoch 191, iter    10] loss: 19.333 eplased time 0.020\n",
      "[epoch 191, iter    20] loss: 21.379 eplased time 0.023\n",
      "[epoch 191, iter    30] loss: 17.710 eplased time 0.022\n",
      "[epoch 191, iter    40] loss: 18.856 eplased time 0.023\n",
      "[epoch 191, iter    50] loss: 20.704 eplased time 0.020\n",
      "[epoch 191, iter    60] loss: 19.545 eplased time 0.020\n",
      "[epoch 191, iter    70] loss: 17.586 eplased time 0.021\n",
      "[epoch 191, iter    80] loss: 18.322 eplased time 0.021\n",
      "[epoch 192, iter    10] loss: 19.814 eplased time 0.020\n",
      "[epoch 192, iter    20] loss: 16.296 eplased time 0.020\n",
      "[epoch 192, iter    30] loss: 16.013 eplased time 0.020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 192, iter    40] loss: 19.149 eplased time 0.023\n",
      "[epoch 192, iter    50] loss: 20.881 eplased time 0.022\n",
      "[epoch 192, iter    60] loss: 20.480 eplased time 0.021\n",
      "[epoch 192, iter    70] loss: 22.328 eplased time 0.021\n",
      "[epoch 192, iter    80] loss: 18.913 eplased time 0.021\n",
      "[epoch 193, iter    10] loss: 20.815 eplased time 0.020\n",
      "[epoch 193, iter    20] loss: 17.777 eplased time 0.021\n",
      "[epoch 193, iter    30] loss: 16.270 eplased time 0.022\n",
      "[epoch 193, iter    40] loss: 21.919 eplased time 0.021\n",
      "[epoch 193, iter    50] loss: 17.187 eplased time 0.020\n",
      "[epoch 193, iter    60] loss: 19.152 eplased time 0.024\n",
      "[epoch 193, iter    70] loss: 19.374 eplased time 0.022\n",
      "[epoch 193, iter    80] loss: 22.149 eplased time 0.021\n",
      "[epoch 194, iter    10] loss: 19.603 eplased time 0.020\n",
      "[epoch 194, iter    20] loss: 20.440 eplased time 0.021\n",
      "[epoch 194, iter    30] loss: 17.847 eplased time 0.020\n",
      "[epoch 194, iter    40] loss: 20.259 eplased time 0.025\n",
      "[epoch 194, iter    50] loss: 19.892 eplased time 0.022\n",
      "[epoch 194, iter    60] loss: 18.710 eplased time 0.020\n",
      "[epoch 194, iter    70] loss: 19.497 eplased time 0.021\n",
      "[epoch 194, iter    80] loss: 18.050 eplased time 0.024\n",
      "[epoch 195, iter    10] loss: 17.696 eplased time 0.022\n",
      "[epoch 195, iter    20] loss: 18.947 eplased time 0.021\n",
      "[epoch 195, iter    30] loss: 17.636 eplased time 0.021\n",
      "[epoch 195, iter    40] loss: 20.246 eplased time 0.020\n",
      "[epoch 195, iter    50] loss: 19.457 eplased time 0.021\n",
      "[epoch 195, iter    60] loss: 21.336 eplased time 0.020\n",
      "[epoch 195, iter    70] loss: 19.780 eplased time 0.020\n",
      "[epoch 195, iter    80] loss: 18.642 eplased time 0.020\n",
      "[epoch 196, iter    10] loss: 18.823 eplased time 0.020\n",
      "[epoch 196, iter    20] loss: 16.881 eplased time 0.024\n",
      "[epoch 196, iter    30] loss: 20.542 eplased time 0.023\n",
      "[epoch 196, iter    40] loss: 19.697 eplased time 0.023\n",
      "[epoch 196, iter    50] loss: 20.165 eplased time 0.024\n",
      "[epoch 196, iter    60] loss: 21.316 eplased time 0.021\n",
      "[epoch 196, iter    70] loss: 19.070 eplased time 0.021\n",
      "[epoch 196, iter    80] loss: 18.423 eplased time 0.021\n",
      "[epoch 197, iter    10] loss: 21.467 eplased time 0.021\n",
      "[epoch 197, iter    20] loss: 17.079 eplased time 0.025\n",
      "[epoch 197, iter    30] loss: 17.569 eplased time 0.023\n",
      "[epoch 197, iter    40] loss: 18.443 eplased time 0.027\n",
      "[epoch 197, iter    50] loss: 21.281 eplased time 0.027\n",
      "[epoch 197, iter    60] loss: 21.646 eplased time 0.024\n",
      "[epoch 197, iter    70] loss: 18.304 eplased time 0.023\n",
      "[epoch 197, iter    80] loss: 18.641 eplased time 0.023\n",
      "[epoch 198, iter    10] loss: 19.465 eplased time 0.021\n",
      "[epoch 198, iter    20] loss: 20.786 eplased time 0.022\n",
      "[epoch 198, iter    30] loss: 19.832 eplased time 0.021\n",
      "[epoch 198, iter    40] loss: 19.588 eplased time 0.024\n",
      "[epoch 198, iter    50] loss: 18.453 eplased time 0.023\n",
      "[epoch 198, iter    60] loss: 19.239 eplased time 0.025\n",
      "[epoch 198, iter    70] loss: 17.863 eplased time 0.021\n",
      "[epoch 198, iter    80] loss: 17.898 eplased time 0.025\n",
      "[epoch 199, iter    10] loss: 20.924 eplased time 0.021\n",
      "[epoch 199, iter    20] loss: 17.052 eplased time 0.021\n",
      "[epoch 199, iter    30] loss: 18.176 eplased time 0.024\n",
      "[epoch 199, iter    40] loss: 19.585 eplased time 0.021\n",
      "[epoch 199, iter    50] loss: 17.855 eplased time 0.024\n",
      "[epoch 199, iter    60] loss: 21.113 eplased time 0.024\n",
      "[epoch 199, iter    70] loss: 20.851 eplased time 0.024\n",
      "[epoch 199, iter    80] loss: 17.774 eplased time 0.020\n",
      "[epoch 200, iter    10] loss: 20.470 eplased time 0.021\n",
      "[epoch 200, iter    20] loss: 20.989 eplased time 0.021\n",
      "[epoch 200, iter    30] loss: 18.510 eplased time 0.021\n",
      "[epoch 200, iter    40] loss: 19.577 eplased time 0.021\n",
      "[epoch 200, iter    50] loss: 19.654 eplased time 0.021\n",
      "[epoch 200, iter    60] loss: 17.180 eplased time 0.021\n",
      "[epoch 200, iter    70] loss: 20.481 eplased time 0.023\n",
      "[epoch 200, iter    80] loss: 17.801 eplased time 0.023\n",
      "[485.86676025390625, 761.5380249023438, 399.6786804199219, 407.8428649902344, 585.9691162109375, 747.82470703125, 553.389404296875, 485.58270263671875, 440.8360595703125, 599.449951171875, 428.6720275878906, 619.8998413085938, 550.927001953125, 574.5706787109375, 591.6189575195312, 465.86004638671875, 535.4004516601562, 440.6601867675781, 539.1155395507812, 571.7744750976562, 714.4344482421875, 390.4952087402344, 742.5625610351562, 577.221923828125, 494.98504638671875, 391.4516906738281, 427.31781005859375, 698.388671875, 558.6575927734375, 579.3346557617188, 428.0018310546875, 461.4743347167969, 504.44366455078125, 552.116455078125, 537.1867065429688, 613.6654663085938, 511.9405822753906, 643.2194213867188, 500.49371337890625, 518.3728637695312, 478.3402099609375, 401.01995849609375, 704.8990478515625, 395.5738525390625, 543.055908203125, 509.1319885253906, 611.811279296875, 344.2924499511719, 395.66925048828125, 682.34912109375, 509.8271789550781, 531.3071899414062, 596.390869140625, 590.2730712890625, 504.35491943359375, 388.0335998535156, 541.4142456054688, 543.692138671875, 491.7744140625, 677.6576538085938, 613.34130859375, 757.0245971679688, 484.7085876464844, 458.1899108886719, 526.7691650390625, 605.453369140625, 292.3368225097656, 564.2208862304688, 530.305419921875, 452.1870422363281, 461.6711730957031, 459.7557373046875, 665.135009765625, 472.8190612792969, 610.50341796875, 523.789794921875, 460.67218017578125, 595.5567626953125, 341.6424255371094, 396.12738037109375, 403.5101623535156, 529.9962158203125, 366.8794860839844, 495.9687194824219, 394.8519592285156, 635.9374389648438, 346.62188720703125, 501.1065368652344, 188.08984375, 524.7774658203125, 575.8661499023438, 454.94891357421875, 310.0343017578125, 644.7189331054688, 470.00445556640625, 364.0930480957031, 549.877197265625, 493.16241455078125, 520.4473266601562, 479.732666015625, 469.02020263671875, 516.3052978515625, 590.3961791992188, 365.8827819824219, 360.4651184082031, 567.94921875, 529.8399047851562, 584.527099609375, 316.4126892089844, 611.2977294921875, 554.184814453125, 441.6719970703125, 542.65673828125, 446.7427673339844, 487.4302062988281, 607.3211669921875, 427.00799560546875, 526.0936889648438, 615.379150390625, 476.6669006347656, 619.253173828125, 291.3394470214844, 713.027099609375, 636.5181884765625, 459.60491943359375, 455.6905822753906, 452.5763244628906, 499.66448974609375, 478.6504211425781, 620.1375122070312, 446.6246337890625, 465.314697265625, 578.8029174804688, 731.4882202148438, 661.9756469726562, 577.2677001953125, 558.05029296875, 623.9428100585938, 423.42742919921875, 461.715576171875, 415.8016052246094, 618.4886474609375, 356.7786865234375, 478.86846923828125, 500.8551025390625, 565.143310546875, 421.2284851074219, 436.1172790527344, 555.4081420898438, 288.895263671875, 326.7817077636719, 455.2704162597656, 508.45635986328125, 488.94476318359375, 354.03350830078125, 592.5239868164062, 592.4094848632812, 534.49755859375, 404.5878601074219, 466.2770690917969, 504.6639404296875, 351.5516662597656, 515.437744140625, 462.72637939453125, 475.61700439453125, 415.70587158203125, 413.7918701171875, 469.2802429199219, 523.066650390625, 504.5550537109375, 545.8464965820312, 516.9343872070312, 460.2229309082031, 608.5145874023438, 272.6012268066406, 576.687744140625, 710.076171875, 420.1630554199219, 346.85382080078125, 314.9407958984375, 533.6312255859375, 501.3194885253906, 575.2113037109375, 437.5047912597656, 542.9024047851562, 377.5909729003906, 404.48101806640625, 293.3691711425781, 460.4593505859375, 416.54840087890625, 543.6390991210938, 429.13787841796875, 414.129638671875, 507.6189880371094, 366.3096923828125, 348.19744873046875, 440.4873962402344, 374.987548828125, 479.4825134277344, 434.7718811035156, 599.761474609375, 405.6470031738281, 454.33563232421875, 529.2266845703125, 321.51416015625, 481.2010192871094, 363.4910583496094, 504.1856689453125, 393.9814758300781, 424.67462158203125, 433.7607727050781, 424.8497619628906, 382.5512390136719, 529.644775390625, 256.9359436035156, 457.22698974609375, 412.0126647949219, 422.10186767578125, 409.3878173828125, 302.2855529785156, 443.7889099121094, 480.6878662109375, 458.1822204589844, 468.67156982421875, 337.056396484375, 413.94647216796875, 276.633056640625, 259.72283935546875, 553.2118530273438, 303.1098937988281, 383.409423828125, 490.5107116699219, 397.0999755859375, 443.6005554199219, 418.2921142578125, 572.5865478515625, 492.67401123046875, 358.16143798828125, 630.8605346679688, 521.9558715820312, 438.1512145996094, 402.8487548828125, 537.9356079101562, 403.62518310546875, 547.1224365234375, 357.62445068359375, 378.7241516113281, 505.2237854003906, 148.8201141357422, 272.7093505859375, 514.195068359375, 380.89886474609375, 532.2105712890625, 521.7130737304688, 319.6192626953125, 466.1250305175781, 350.31903076171875, 541.6423950195312, 509.7325134277344, 317.43865966796875, 272.72467041015625, 434.0513916015625, 315.55474853515625, 457.2582092285156, 364.4516906738281, 395.7378234863281, 407.8233642578125, 358.71636962890625, 442.4230041503906, 537.9375610351562, 378.4466857910156, 487.75311279296875, 439.5536193847656, 462.4541931152344, 398.544189453125, 313.1015319824219, 461.15386962890625, 525.2597045898438, 431.5605773925781, 509.0606384277344, 357.2657470703125, 353.7584228515625, 559.446533203125, 434.3344421386719, 473.4447021484375, 366.84991455078125, 238.25527954101562, 300.74786376953125, 409.7420959472656, 414.4410400390625, 501.9365234375, 374.0235900878906, 577.3085327148438, 284.0093994140625, 301.71673583984375, 288.6322937011719, 357.6326599121094, 467.5315246582031, 511.0478210449219, 566.94677734375, 569.4468994140625, 124.93534851074219, 354.283935546875, 306.1797180175781, 594.7841186523438, 347.88299560546875, 505.38409423828125, 388.0985412597656, 196.20262145996094, 520.9046630859375, 448.6043701171875, 378.92578125, 216.7246856689453, 267.8213806152344, 430.1063232421875, 336.4472351074219, 524.1209106445312, 618.2383422851562, 328.9668884277344, 389.87811279296875, 413.2858581542969, 431.3765563964844, 344.2904968261719, 494.2011413574219, 347.30621337890625, 425.8119812011719, 322.9530944824219, 161.4451141357422, 303.0845031738281, 144.23355102539062, 396.7681884765625, 432.251953125, 410.3376159667969, 486.2215270996094, 351.9709777832031, 281.2900695800781, 398.8969421386719, 318.1902770996094, 376.0802001953125, 248.43447875976562, 334.1522521972656, 345.4604187011719, 295.9848937988281, 360.694091796875, 314.3427734375, 269.4199523925781, 432.73309326171875, 469.0693664550781, 512.5831298828125, 319.3077697753906, 304.4312744140625, 395.1328125, 511.1534423828125, 383.0750427246094, 462.19989013671875, 531.9159545898438, 237.63345336914062, 426.35687255859375, 408.06121826171875, 362.1611328125, 376.3683166503906, 181.48712158203125, 417.9985046386719, 355.71697998046875, 457.0269470214844, 377.9308166503906, 340.452880859375, 239.13272094726562, 247.5713348388672, 223.6870574951172, 400.6104736328125, 310.91729736328125, 420.218994140625, 434.932373046875, 401.4225769042969, 192.95115661621094, 258.41619873046875, 377.5313720703125, 451.4301452636719, 242.1387481689453, 588.9094848632812, 325.83319091796875, 400.346923828125, 287.2815246582031, 334.1094970703125, 287.402099609375, 320.45721435546875, 356.040283203125, 506.702392578125, 371.7278137207031, 186.14698791503906, 310.7796936035156, 472.013671875, 347.9246826171875, 187.6430206298828, 391.4593505859375, 464.9013977050781, 294.8515319824219, 375.3685607910156, 470.90191650390625, 345.5296630859375, 416.02313232421875, 266.9341735839844, 437.84234619140625, 269.6236572265625, 187.55615234375, 249.08740234375, 431.0170593261719, 531.653076171875, 374.18402099609375, 219.5240020751953, 213.43406677246094, 387.1174621582031, 198.6110382080078, 346.9472961425781, 302.707763671875, 192.9253692626953, 312.84246826171875, 414.7986755371094, 224.49656677246094, 438.9994812011719, 181.42799377441406, 306.7035217285156, 263.9464111328125, 239.10366821289062, 275.5767822265625, 380.6607360839844, 294.614501953125, 205.18113708496094, 256.8940734863281, 412.3998718261719, 159.8914337158203, 148.50241088867188, 190.44180297851562, 191.93301391601562, 263.2950134277344, 301.8468933105469, 287.9938049316406, 440.7248840332031, 108.33329772949219, 248.7307586669922, 306.0479431152344, 508.94586181640625, 327.2723388671875, 277.77191162109375, 385.2256774902344, 228.5640869140625, 323.12054443359375, 429.76055908203125, 415.12042236328125, 337.4908447265625, 317.42816162109375, 501.40545654296875, 353.0792541503906, 460.0614318847656, 195.59793090820312, 321.97003173828125, 375.8940734863281, 296.7015686035156, 357.2572021484375, 383.4189147949219, 525.1867065429688, 463.3263244628906, 325.6391296386719, 265.65948486328125, 423.41925048828125, 318.7627258300781, 373.5247802734375, 150.0538330078125, 433.5881652832031, 223.4781036376953, 351.6617431640625, 334.4750061035156, 443.6875915527344, 368.049560546875, 375.382568359375, 216.58456420898438, 158.9713134765625, 435.4698791503906, 279.8150634765625, 346.884765625, 140.60858154296875, 281.3793640136719, 405.0235290527344, 212.5634002685547, 330.697265625, 319.47698974609375, 262.720947265625, 425.22222900390625, 243.0579071044922, 318.02545166015625, 406.3344421386719, 173.22091674804688, 268.2798767089844, 306.9359130859375, 334.3871154785156, 337.1175842285156, 320.0278015136719, 322.479736328125, 220.7152099609375, 210.4577178955078, 130.1935272216797, 253.72315979003906, 485.4947509765625, 252.77174377441406, 318.89874267578125, 318.0218200683594, 312.2729187011719, 348.6908264160156, 296.0437316894531, 353.9813232421875, 393.5093078613281, 451.8671569824219, 337.5926818847656, 390.32733154296875, 493.16534423828125, 210.68016052246094, 265.4292907714844, 254.56060791015625, 187.04734802246094, 343.7245178222656, 337.65594482421875, 308.6390686035156, 177.91038513183594, 127.66570281982422, 333.6078186035156, 212.2029266357422, 182.51715087890625, 230.03115844726562, 343.1184387207031, 365.596435546875, 359.4226989746094, 325.8756103515625, 163.62808227539062, 244.3717803955078, 193.51260375976562, 207.99855041503906, 358.1302490234375, 331.7119140625, 380.259521484375, 394.4160461425781, 257.9073181152344, 309.71923828125, 374.6604309082031, 218.19229125976562, 200.3531036376953, 259.1324462890625, 439.91241455078125, 278.48272705078125, 234.1748504638672, 455.36871337890625, 182.33277893066406, 340.237548828125, 350.7843017578125, 225.21649169921875, 195.74525451660156, 246.99093627929688, 267.9301452636719, 295.769775390625, 277.0260009765625, 414.4591369628906, 286.4306945800781, 146.0046844482422, 302.3655700683594, 213.43798828125, 238.7636260986328, 412.62774658203125, 204.8026123046875, 367.3041687011719, 291.4294128417969, 300.60772705078125, 288.5046691894531, 149.55140686035156, 250.5102081298828, 240.82029724121094, 209.23556518554688, 232.37680053710938, 315.5551452636719, 290.3421630859375, 275.9580383300781, 332.1504821777344, 301.128173828125, 189.72486877441406, 277.8813171386719, 307.757080078125, 280.1295166015625, 392.0687561035156, 246.82342529296875, 213.98785400390625, 366.3565368652344, 332.076904296875, 207.4082794189453, 175.7635498046875, 373.8252258300781, 290.55621337890625, 279.3354797363281, 111.81794738769531, 380.5482482910156, 233.49070739746094, 314.0733642578125, 203.6141815185547, 189.2006378173828, 264.0019836425781, 379.7538146972656, 386.43865966796875, 386.44769287109375, 222.4084014892578, 474.5627746582031, 344.22296142578125, 151.52188110351562, 221.03025817871094, 279.2496643066406, 149.22955322265625, 362.6326904296875, 268.9857177734375, 208.5360565185547, 137.23377990722656, 426.4284362792969, 230.57220458984375, 215.49888610839844, 175.3703155517578, 359.20550537109375, 263.35986328125, 377.9377746582031, 249.98268127441406, 352.9581604003906, 166.30154418945312, 390.6748046875, 394.253662109375, 215.67503356933594, 227.7825164794922, 132.70938110351562, 296.8853759765625, 422.0920715332031, 348.99188232421875, 252.3860321044922, 243.35037231445312, 471.15118408203125, 225.1371612548828, 173.36351013183594, 281.2900695800781, 312.9036865234375, 148.87261962890625, 199.94061279296875, 194.85952758789062, 371.7521057128906, 218.70428466796875, 362.0710144042969, 201.2655029296875, 348.34515380859375, 225.7787322998047, 169.3350830078125, 237.5172882080078, 354.6874694824219, 362.8321838378906, 258.3945617675781, 235.49485778808594, 248.02658081054688, 238.39430236816406, 117.70307922363281, 281.6955261230469, 213.06947326660156, 265.5254821777344, 322.8415222167969, 102.8539810180664, 296.5391540527344, 250.54371643066406, 340.1159362792969, 336.58734130859375, 377.75274658203125, 252.6665496826172, 293.4682312011719, 271.2390441894531, 299.6124267578125, 222.14891052246094, 202.17437744140625, 220.90469360351562, 269.03717041015625, 326.6581115722656, 244.97341918945312, 252.6724853515625, 218.05914306640625, 261.6014404296875, 264.13543701171875, 228.99559020996094, 286.79364013671875, 381.1319274902344, 197.4844207763672, 198.72642517089844, 285.7604675292969, 341.3929748535156, 180.0702667236328, 258.3720397949219, 231.13009643554688, 329.4719543457031, 357.81793212890625, 310.48272705078125, 340.86859130859375, 215.12289428710938, 287.5827941894531, 242.17507934570312, 341.7613525390625, 180.37681579589844, 93.15467071533203, 337.5064392089844, 215.36685180664062, 141.75857543945312, 383.008544921875, 443.51885986328125, 231.1004638671875, 378.1080017089844, 347.5895690917969, 195.0229034423828, 117.13977813720703, 313.78656005859375, 246.1795654296875, 286.2984313964844, 231.07064819335938, 223.14698791503906, 247.87384033203125, 294.3533935546875, 382.8406982421875, 229.34742736816406, 160.17828369140625, 315.50628662109375, 177.5897674560547, 139.7367706298828, 315.51239013671875, 261.4828186035156, 205.91107177734375, 241.95872497558594, 247.07199096679688, 350.9809265136719, 333.3746337890625, 173.34007263183594, 245.43284606933594, 204.5952606201172, 225.85922241210938, 214.1848602294922, 307.1407470703125, 412.9347229003906, 326.5347595214844, 229.62466430664062, 384.02178955078125, 136.78684997558594, 246.62376403808594, 280.6000061035156, 164.71559143066406, 165.30203247070312, 257.6045227050781, 155.79531860351562, 252.99749755859375, 243.3266143798828, 206.35044860839844, 165.2064666748047, 280.85748291015625, 275.4019470214844, 348.8887939453125, 212.64845275878906, 282.79217529296875, 205.30313110351562, 216.4297332763672, 304.748779296875, 281.3184509277344, 225.38583374023438, 213.91513061523438, 112.54943084716797, 248.38909912109375, 201.08685302734375, 248.6120147705078, 358.9990539550781, 218.6483154296875, 199.57862854003906, 174.10882568359375, 296.0328369140625, 175.36578369140625, 309.6370849609375, 174.20777893066406, 249.01734924316406, 192.4359588623047, 251.97348022460938, 193.68800354003906, 291.8598937988281, 262.1637878417969, 206.41082763671875, 265.8045959472656, 222.42440795898438, 218.62869262695312, 142.05157470703125, 260.06878662109375, 200.79315185546875, 220.8389129638672, 256.23870849609375, 306.4646911621094, 374.8872375488281, 381.957763671875, 302.96844482421875, 194.11558532714844, 125.4303970336914, 178.8291015625, 167.03961181640625, 287.1953430175781, 344.9786071777344, 161.45077514648438, 128.34532165527344, 258.73077392578125, 261.6011657714844, 216.42347717285156, 135.10960388183594, 214.82044982910156, 261.7464904785156, 250.8394317626953, 155.37832641601562, 262.5530090332031, 224.29986572265625, 195.04373168945312, 344.7798156738281, 236.4628143310547, 144.1842041015625, 294.7265319824219, 109.38919067382812, 273.0155334472656, 200.94830322265625, 136.69529724121094, 170.4193572998047, 227.5251007080078, 287.1785888671875, 95.09764862060547, 260.8774719238281, 199.9122314453125, 218.9635009765625, 297.5578918457031, 195.66966247558594, 168.38516235351562, 150.77317810058594, 273.2968444824219, 286.58740234375, 155.48744201660156, 321.7209167480469, 262.9198913574219, 286.9419250488281, 234.14691162109375, 219.39576721191406, 161.74781799316406, 167.48052978515625, 184.98992919921875, 191.24986267089844, 131.2744598388672, 213.2417449951172, 239.24781799316406, 191.2524871826172, 159.62713623046875, 276.9642639160156, 152.9080810546875, 245.5124053955078, 112.72158813476562, 136.64141845703125, 325.1983642578125, 301.2510070800781, 261.6501770019531, 277.9624938964844, 104.72734069824219, 68.83914184570312, 238.45494079589844, 335.6134033203125, 182.46405029296875, 182.1879119873047, 194.5489501953125, 348.6896057128906, 162.32363891601562, 173.75619506835938, 224.78564453125, 220.49559020996094, 252.47177124023438, 239.08099365234375, 218.7152862548828, 150.6882781982422, 222.4541473388672, 292.5933837890625, 338.4253845214844, 234.89036560058594, 301.4264831542969, 229.8625946044922, 222.38922119140625, 202.6505126953125, 288.2688903808594, 229.4894561767578, 182.17031860351562, 223.73890686035156, 260.5440979003906, 198.37982177734375, 258.15594482421875, 205.93922424316406, 202.8000030517578, 201.0858917236328, 271.14532470703125, 262.9839172363281, 218.13169860839844, 44.933170318603516, 295.1921081542969, 250.52394104003906, 303.3887634277344, 309.9668884277344, 188.08767700195312, 198.8111114501953, 177.1548614501953, 196.07347106933594, 190.5429229736328, 179.21351623535156, 383.2648010253906, 294.5143127441406, 258.42706298828125, 346.0552062988281, 241.0578155517578, 195.1993408203125, 298.31396484375, 266.4598388671875, 262.00323486328125, 372.9330139160156, 223.08863830566406, 170.6900177001953, 237.85939025878906, 76.67111206054688, 247.67471313476562, 200.50628662109375, 119.72827911376953, 334.7590637207031, 157.78067016601562, 316.932861328125, 187.85772705078125, 186.80455017089844, 191.7451629638672, 193.87281799316406, 207.6009521484375, 152.95310974121094, 141.28436279296875, 188.63241577148438, 222.2453155517578, 303.4792785644531, 236.70941162109375, 182.5688934326172, 341.2044982910156, 143.6564483642578, 295.1895446777344, 184.5614471435547, 203.8782958984375, 229.3092803955078, 291.4941101074219, 220.84542846679688, 208.16729736328125, 242.21783447265625, 346.0623779296875, 261.2019348144531, 242.68240356445312, 147.05076599121094, 297.6560974121094, 149.63458251953125, 309.12908935546875, 183.7972869873047, 151.1995086669922, 248.94219970703125, 226.5099639892578, 375.2357482910156, 333.06915283203125, 166.29217529296875, 251.24281311035156, 182.01776123046875, 169.99554443359375, 174.94947814941406, 174.1640167236328, 142.7041778564453, 228.45004272460938, 201.2031707763672, 167.04905700683594, 357.1014404296875, 257.6485595703125, 188.0629425048828, 231.26394653320312, 126.68063354492188, 144.97166442871094, 272.3480529785156, 311.48162841796875, 124.61273193359375, 250.53915405273438, 221.61550903320312, 179.2281036376953, 276.396728515625, 110.09054565429688, 255.71240234375, 165.84303283691406, 164.3179473876953, 172.2104034423828, 170.6674346923828, 278.47943115234375, 179.70851135253906, 210.23953247070312, 252.7300567626953, 273.9139709472656, 240.59561157226562, 209.80250549316406, 195.2615966796875, 151.673583984375, 217.39297485351562, 236.35325622558594, 191.07498168945312, 250.7307586669922, 224.6016845703125, 204.59878540039062, 141.52557373046875, 145.0286865234375, 229.2615203857422, 261.5410461425781, 228.9405059814453, 189.33009338378906, 158.63307189941406, 142.26266479492188, 245.81402587890625, 138.53573608398438, 136.3633575439453, 264.7968444824219, 135.14453125, 161.521240234375, 246.1887664794922, 243.82772827148438, 297.8452453613281, 206.26869201660156, 167.27908325195312, 157.7553253173828, 188.48191833496094, 104.08509826660156, 225.02357482910156, 232.10165405273438, 153.29458618164062, 231.38783264160156, 310.8700866699219, 195.0879669189453, 151.1062469482422, 164.95684814453125, 201.73756408691406, 170.74461364746094, 244.8328094482422, 120.95877075195312, 187.078125, 300.4183654785156, 264.4311218261719, 172.0317840576172, 150.6906280517578, 259.13623046875, 154.8193359375, 321.2040710449219, 275.6615905761719, 190.56390380859375, 174.75137329101562, 246.6172332763672, 188.28492736816406, 331.6655578613281, 178.68539428710938, 257.37066650390625, 164.94277954101562, 226.2327880859375, 207.62319946289062, 215.28549194335938, 194.17758178710938, 199.1826934814453, 212.46661376953125, 182.5281219482422, 241.51589965820312, 212.50453186035156, 200.7021942138672, 279.7359619140625, 187.77146911621094, 195.46778869628906, 192.48214721679688, 179.6420440673828, 165.39535522460938, 131.6919708251953, 231.47447204589844, 248.9270477294922, 322.1871337890625, 267.62213134765625, 163.75628662109375, 199.63296508789062, 234.91900634765625, 146.09544372558594, 262.7373962402344, 140.6674346923828, 237.72964477539062, 138.6853790283203, 287.036376953125, 276.162841796875, 199.0827178955078, 227.30978393554688, 147.44993591308594, 237.58180236816406, 175.13539123535156, 217.6723175048828, 216.33480834960938, 268.7423400878906, 272.129638671875, 199.9454345703125, 223.06263732910156, 258.552001953125, 224.36566162109375, 287.0968933105469, 184.98582458496094, 109.03096008300781, 261.2777404785156, 147.25082397460938, 251.43594360351562, 178.58364868164062, 132.92416381835938, 252.6719207763672, 273.69842529296875, 240.7375030517578, 62.15106964111328, 227.52142333984375, 174.20533752441406, 202.89230346679688, 246.3621826171875, 185.73536682128906, 267.8576965332031, 242.18865966796875, 260.646728515625, 359.10577392578125, 241.53082275390625, 228.5780792236328, 311.6471862792969, 218.17129516601562, 310.52459716796875, 214.3384552001953, 236.1296844482422, 217.50607299804688, 239.81668090820312, 268.1121520996094, 166.85610961914062, 209.47320556640625, 203.15985107421875, 262.17022705078125, 201.8953094482422, 193.74063110351562, 137.22210693359375, 304.3436279296875, 189.58905029296875, 145.05865478515625, 156.38778686523438, 177.15472412109375, 236.88478088378906, 243.87799072265625, 257.7519836425781, 162.02064514160156, 236.24569702148438, 248.9105987548828, 220.2984161376953, 193.78285217285156, 236.46713256835938, 220.97532653808594, 193.68687438964844, 124.07969665527344, 183.39913940429688, 212.14630126953125, 140.46327209472656, 222.39898681640625, 209.04832458496094, 161.71859741210938, 236.68701171875, 121.858642578125, 156.9009552001953, 204.4004669189453, 154.55935668945312, 115.33907318115234, 188.2890625, 269.02001953125, 226.97145080566406, 150.7890625, 117.1783218383789, 245.70626831054688, 231.86354064941406, 237.30783081054688, 186.38645935058594, 264.6015930175781, 198.0225067138672, 159.9421844482422, 240.08334350585938, 207.43421936035156, 151.55718994140625, 175.7100830078125, 156.0544891357422, 171.99449157714844, 235.4281463623047, 241.76876831054688, 208.58609008789062, 106.7015609741211, 103.96102905273438, 186.13539123535156, 202.83917236328125, 164.7992401123047, 235.44268798828125, 222.95144653320312, 124.96947479248047, 177.2078094482422, 170.3432159423828, 216.04017639160156, 240.5764617919922, 161.0846710205078, 311.132568359375, 213.4501495361328, 188.4496612548828, 201.33216857910156, 124.3218765258789, 174.3845672607422, 181.5105438232422, 282.7934265136719, 177.31007385253906, 113.1091537475586, 199.8560791015625, 139.08135986328125, 148.94557189941406, 131.62425231933594, 130.80917358398438, 269.4985656738281, 197.72705078125, 220.62486267089844, 113.7569808959961, 248.99673461914062, 209.54443359375, 271.4754638671875, 200.30337524414062, 204.9911346435547, 167.06549072265625, 220.70884704589844, 272.6798095703125, 229.1545867919922, 200.7865753173828, 224.6188507080078, 166.9491729736328, 198.10565185546875, 204.35479736328125, 212.6942138671875, 276.7922058105469, 208.0390625, 200.72592163085938, 242.52146911621094, 126.26172637939453, 302.2295837402344, 172.2140655517578, 173.62118530273438, 300.5453186035156, 158.70294189453125, 291.9556884765625, 159.64218139648438, 179.75579833984375, 249.2168731689453, 265.3297119140625, 114.5703353881836, 134.9971160888672, 171.0376434326172, 150.40548706054688, 127.62974548339844, 150.82716369628906, 276.5, 196.48110961914062, 267.53643798828125, 233.7277374267578, 196.82183837890625, 237.201171875, 132.91400146484375, 192.12973022460938, 213.52833557128906, 227.3880615234375, 124.35779571533203, 146.7581024169922, 240.7001190185547, 136.3766632080078, 198.6631317138672, 150.35467529296875, 296.6328430175781, 177.85105895996094, 184.19161987304688, 180.5833740234375, 116.37046813964844, 149.32826232910156, 177.88394165039062, 124.53296661376953, 244.39688110351562, 165.6345672607422, 151.4359893798828, 104.7553939819336, 249.94570922851562, 214.06622314453125, 177.50367736816406, 209.25, 186.18130493164062, 251.20831298828125, 71.00870513916016, 217.97657775878906, 226.14060974121094, 73.09803009033203, 253.6760711669922, 124.35865020751953, 118.4984359741211, 188.01577758789062, 100.50157165527344, 185.99639892578125, 291.89410400390625, 182.90574645996094, 205.18984985351562, 137.8072509765625, 160.80923461914062, 198.93154907226562, 258.2500305175781, 134.49693298339844, 248.9965057373047, 160.5961456298828, 234.1746826171875, 217.47361755371094, 211.22535705566406, 115.31156921386719, 153.91546630859375, 135.34083557128906, 191.99685668945312, 217.04954528808594, 249.9286346435547, 186.07981872558594, 249.97705078125, 130.0015106201172, 151.03030395507812, 160.96249389648438, 250.52810668945312, 165.51547241210938, 225.31932067871094, 219.24591064453125, 205.8140411376953, 195.6323699951172, 282.7671813964844, 147.06167602539062, 240.38796997070312, 171.68626403808594, 324.7495422363281, 160.41773986816406, 130.074462890625, 191.54322814941406, 233.70144653320312, 214.48388671875, 221.73223876953125, 167.74545288085938, 284.5078125, 186.61203002929688, 109.88524627685547, 184.84304809570312, 252.4093017578125, 228.19847106933594, 253.25271606445312, 224.87965393066406, 204.01187133789062, 235.849609375, 144.60784912109375, 198.70884704589844, 189.70066833496094, 141.80157470703125, 199.85572814941406, 213.43124389648438, 139.60882568359375, 197.4176788330078, 237.24957275390625, 266.7201843261719, 125.71743774414062, 175.4631805419922, 145.4376678466797, 174.20611572265625, 202.75314331054688, 200.43772888183594, 275.7012023925781, 263.7967834472656, 230.5873565673828, 209.1885986328125, 186.99203491210938, 259.1434020996094, 204.33120727539062, 167.66635131835938, 234.7484893798828, 217.31283569335938, 295.504638671875, 256.6703796386719, 256.5381774902344, 236.4058074951172, 195.43276977539062, 237.44839477539062, 213.33926391601562, 207.31671142578125, 167.79859924316406, 260.2378845214844, 167.4610595703125, 140.720947265625, 262.4251403808594, 165.73886108398438, 175.7220458984375, 124.49694061279297, 228.32228088378906, 162.3087921142578, 254.9828338623047, 229.62240600585938, 162.2257843017578, 187.13735961914062, 262.2255554199219, 224.68325805664062, 164.9084014892578, 145.5679168701172, 204.3509521484375, 208.83294677734375, 81.10771179199219, 130.62782287597656, 270.57196044921875, 217.2035675048828, 215.97451782226562, 226.5840606689453, 265.3575439453125, 151.3796844482422, 212.79078674316406, 208.79061889648438, 293.14520263671875, 228.87979125976562, 196.9188995361328, 189.49586486816406, 138.8137969970703, 155.09840393066406, 150.9687042236328, 201.1421661376953, 182.36439514160156, 124.4192886352539, 165.56166076660156, 164.34848022460938, 208.85479736328125, 82.3397445678711, 170.96563720703125, 189.36297607421875, 217.88449096679688, 177.26577758789062, 206.89691162109375, 197.52293395996094, 270.67022705078125, 201.65794372558594, 241.0277099609375, 186.40298461914062, 223.8642578125, 267.0171813964844, 229.50146484375, 174.17494201660156, 96.90929412841797, 156.1163330078125, 150.05609130859375, 277.8221435546875, 223.3900604248047, 206.3990478515625, 74.53781127929688, 230.37811279296875, 174.4869384765625, 168.2859344482422, 148.72947692871094, 189.8203125, 143.10076904296875, 151.40155029296875, 244.73757934570312, 267.84521484375, 103.14141845703125, 170.09959411621094, 201.12672424316406, 119.20545196533203, 169.71714782714844, 195.92359924316406, 145.13217163085938, 164.75132751464844, 179.18177795410156, 191.42906188964844, 158.48358154296875, 216.28598022460938, 152.8701171875, 199.7391815185547, 116.00686645507812, 169.33746337890625, 157.52951049804688, 93.34400177001953, 226.5815887451172, 185.86544799804688, 232.89744567871094, 69.0910415649414, 136.0360107421875, 235.08180236816406, 246.2046661376953, 169.24143981933594, 191.82562255859375, 194.0135498046875, 187.94671630859375, 208.3379669189453, 120.93592834472656, 215.6173095703125, 235.71261596679688, 169.1015625, 215.10057067871094, 136.60914611816406, 157.48422241210938, 249.0159149169922, 193.8485565185547, 184.8135528564453, 187.50421142578125, 290.8390808105469, 216.71359252929688, 260.3277587890625, 169.34445190429688, 164.55470275878906, 299.3349609375, 158.95448303222656, 210.89808654785156, 151.81021118164062, 157.63046264648438, 206.41561889648438, 242.65011596679688, 211.87184143066406, 112.7234878540039, 135.90859985351562, 217.72601318359375, 175.6514129638672, 188.21043395996094, 123.20765686035156, 197.20787048339844, 326.5859375, 161.76185607910156, 240.13336181640625, 173.08082580566406, 182.09584045410156, 203.27980041503906, 141.46463012695312, 239.2394561767578, 213.6296844482422, 215.8810577392578, 221.75650024414062, 138.79212951660156, 252.2526397705078, 170.29769897460938, 227.6566619873047, 313.6219482421875, 226.9953155517578, 187.0046844482422, 226.99322509765625, 227.82354736328125, 222.38853454589844, 125.05155181884766, 222.9609832763672, 224.56248474121094, 254.90501403808594, 230.82177734375, 214.5082550048828, 139.49765014648438, 198.97821044921875, 143.32351684570312, 184.20208740234375, 190.05609130859375, 234.96360778808594, 253.94642639160156, 205.7938690185547, 260.6182861328125, 227.53549194335938, 205.54217529296875, 227.49261474609375, 242.1198272705078, 263.0723571777344, 203.9625244140625, 161.57484436035156, 192.79074096679688, 182.57357788085938, 181.9810791015625, 174.5546417236328, 184.80628967285156, 235.3846893310547, 213.6765594482422, 132.5000457763672, 205.8582763671875, 214.5924835205078, 198.55795288085938, 138.24063110351562, 248.5293731689453, 178.6005859375, 217.7484588623047, 161.99472045898438, 218.38827514648438, 180.10572814941406, 179.49200439453125, 191.9624481201172, 175.2730255126953, 161.9679718017578, 239.6219940185547, 269.3932800292969, 208.21775817871094, 120.24557495117188, 160.84588623046875, 153.33901977539062, 245.099609375, 190.34165954589844, 156.55799865722656, 250.40574645996094, 202.41546630859375]\n",
      "Finished Training\n",
      "Error: 191 dollars\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#Takes in csv file and loads it so that it is a pytorch tensor for training and testing data\n",
    "def loader():\n",
    "\tX_train, y_train, X_test, y_test = None, None, None, None\n",
    "\n",
    "\t#Read csv file and drop unncecessary columns\n",
    "\tdata = pd.read_csv('combined_data.csv')\n",
    "\tdata = data.drop(data.columns[0], axis=1)\n",
    "\tdata = data.drop(['LAST','FIRST','ID','MIDDLE','APPT FTR BASIS','APPT FRACTION','AMT OF SALARY PAID FROM GENL FUND',\n",
    "\t\t'FOS', 'Middle', 'url', 'X1', 'found'], axis=1)\n",
    "\tdata = data.drop(data.columns[17], axis=1)\n",
    "\n",
    "\t#Get number of unique values\n",
    "\tcolumns = list(data.columns.values)\n",
    "\tunique_vals_set = set()\n",
    "\tfor i in columns:\n",
    "\t\tunique_vals_set.update(set(data[i].unique().tolist()))\n",
    "\tunique_vals = len(unique_vals_set)\n",
    "\n",
    "\tunique_vals_list = list(unique_vals_set)\n",
    "\n",
    "\tindex = 1\n",
    "\tdictionary = {'NaN':0}\n",
    "\tfor index, val in enumerate(unique_vals_list):\n",
    "\t\tif val not in dictionary:\n",
    "\t\t\tdictionary[unique_vals_list[index]] = index\n",
    "\t\t\tindex += 1\n",
    "\n",
    "\tdata = data.replace(dictionary)\n",
    "\n",
    "\t#Turn data to numpy array\n",
    "\tdata = data.values\n",
    "\n",
    "\t#Full dataset variables of X and Y\n",
    "\ty_vals = data[:, 16]\n",
    "\tX_vals = data[:,:16]\n",
    "\tindices = np.random.permutation(y_vals.shape[0])\n",
    "\ttraining_idx, test_idx = indices[:math.floor(y_vals.shape[0] * 0.9)], indices[math.floor(y_vals.shape[0] * 0.9):]\n",
    "\t\n",
    "\tX_train = X_vals[training_idx, :]\n",
    "\tX_test = X_vals[test_idx,:]\n",
    "\ty_train = y_vals[training_idx]\n",
    "\ty_test = y_vals[test_idx]\n",
    "\n",
    "\n",
    "\n",
    "\treturn X_train, y_train, X_test, y_test, unique_vals\n",
    "\n",
    "\n",
    "#Our Model's class\n",
    "class NeuralNet(nn.Module):\n",
    "\tdef __init__(self, embed_units, hidden_units1=50, hidden_units2=100, output_units=1, inp_units=20):\n",
    "\t\tsuper().__init__()\n",
    "\n",
    "\t\t#Change these to our liking. Maybe add Batchnorm or L2 Normalization?\n",
    "\t\t#Also maybe do weight initialization ourselves?\n",
    "\n",
    "\t\tself.embed = nn.Embedding(embed_units, 18) #Figure out how we want to do embedding\n",
    "\t\tself.fc = nn.Sequential(\n",
    "\t\t\t# N x ? tensor (? WILL BE KNOWN ONCE EMBEDDING HAS BEEN IMPLEMENTED)\n",
    "\t\t\tnn.Linear(18, hidden_units1),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.Dropout(0.2),\n",
    "\t\t\t# N x 100 tensor\n",
    "\t\t\tnn.Linear(hidden_units1, hidden_units2),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.Dropout(0.1),\n",
    "\t\t\t# N x 200 tensor\n",
    "\t\t\tnn.Linear(hidden_units2, hidden_units1),\n",
    "\t\t\tnn.Tanh(),\n",
    "\t\t\t# N x 100 tensor\n",
    "\t\t\tnn.Linear(hidden_units1,output_units),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "\t\t\t# N x 1 tensor\n",
    "\t\t\t)\n",
    "\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# x is an N x dim tensor\n",
    "\t\ty_hat = self.embed(x.long()) #Add the embedding once figured out\n",
    "\t\ty_hat = self.fc(y_hat) \n",
    "\t\treturn y_hat\n",
    "\n",
    "#Set weights of model\n",
    "def init_weights(m):\n",
    "\tif type(m) == nn.Linear:\n",
    "\t\ttorch.nn.init.xavier_uniform(m.weight)\n",
    "\t\tm.bias.data.fill_(0.01)\n",
    "\n",
    "def NeuralTrain(trainloader, net, criterion, optimizer, device):\n",
    "\tloss_graph = []\n",
    "\tfor epoch in range(200):  # loop over the dataset for x number of epochs\n",
    "\t\tstart = time.time()\n",
    "\t\trunning_loss = 0.0\n",
    "\n",
    "\t\t#For each batch run through model, backprop, and optimize weights\n",
    "\t\tfor i, (data, salary) in enumerate(trainloader):\n",
    "\t\t\tdata = data.to(device).float()\n",
    "\t\t\tsalary = salary.to(device).float()\n",
    "\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\toutput = net(data)\n",
    "\t\t\tloss = criterion(output, salary)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\t# print statistics\n",
    "\t\t\trunning_loss += loss.item()\n",
    "\t\t\t\n",
    "\t\t\tif i % 10 == 9:\n",
    "\t\t\t\tloss_graph.append(loss.item())\n",
    "\t\t\t\tend = time.time()\n",
    "\t\t\t\tprint('[epoch %d, iter %5d] loss: %.3f eplased time %.3f' % \n",
    "\t\t\t\t\t(epoch + 1, i + 1, running_loss / 100, end - start))\n",
    "\t\t\t\tstart = time.time()\n",
    "\t\t\t\trunning_loss = 0.0\n",
    "    \n",
    "\t# Plot learning curve\n",
    "\tfig1, ax1 = plt.subplots()\n",
    "\tax1.plot(loss_graph, '--')\n",
    "\tax1.set_title('Learning curve.')\n",
    "\tax1.set_ylabel('MSE')\n",
    "\tax1.set_xlabel('Optimization steps.')\n",
    "\n",
    "\tprint('Finished Training')\n",
    "\n",
    "def NeuralTest(testloader, net, criterion, device):\n",
    "\ttotal = 0\n",
    "\terror = []\n",
    "\tfig2, ax2 = plt.subplots()\n",
    "\twith torch.no_grad():\n",
    "\t\tfor data in testloader:\n",
    "\t\t\trepresentations, salary = data\n",
    "\t\t\trepresentations = representations.to(device).float()\n",
    "\t\t\tsalary = salary.to(device).float()\n",
    "\t\t\toutputs = net(representations)\n",
    "\t\t\tloss = criterion(outputs, salary)\n",
    "\t\t\t'''\n",
    "\t\t\tax2.plot(outputs.numpy(), salary.numpy(), 'r+')\n",
    "\t\t\tax2.set_title('Prediction Plot')\n",
    "\t\t\tax2.set_ylabel('Actual Salary')\n",
    "\t\t\tax2.set_xlabel('Prediction')\n",
    "\t\t\t'''\n",
    "\t\t\terror.append(loss)\n",
    "\tprint('Error: %d dollars' % (np.mean(error)))\n",
    "\n",
    "def main():\n",
    "\t#Sets device to cpu or gpu if you have one\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\t#Get our datasets loaded\n",
    "\tX_train, y_train, X_test, y_test, unique_vals = loader()\n",
    "\n",
    "\t#Turn numpy matrices into pytorch tensors for neural network\n",
    "\t#Turn numpy matrices into pytorch tensors for neural network\n",
    "\tX_train = torch.tensor(X_train.astype(dtype = 'float32'))\n",
    "\ty_train = torch.tensor(y_train.astype(dtype = 'float32'))\n",
    "\tX_test = torch.tensor(X_test.astype(dtype = 'float32'))\n",
    "\ty_test = torch.tensor(y_test.astype(dtype = 'float32'))\n",
    "\n",
    "\t#Put them into torch datasets with batch size \n",
    "\t#BATCH SIZE CAN CHANGE TO WHATEVER WORKS BEST\n",
    "\ttrainset = data_utils.TensorDataset(X_train, y_train)\n",
    "\ttrainloader = torch.utils.data.DataLoader(trainset, batch_size=5, shuffle=True)\n",
    "\n",
    "\ttestset = data_utils.TensorDataset(X_test, y_test)\n",
    "\ttestloader = torch.utils.data.DataLoader(testset, batch_size=y_test.shape[0], shuffle=False)\n",
    "\n",
    "\t#Model and Loss\n",
    "\tnet = NeuralNet(embed_units=unique_vals).to(device)\n",
    "\tnet.apply(init_weights)\n",
    "\tcriterion = nn.L1Loss()\n",
    "\n",
    "\t#Can also switch from adam to sgd if we so choose\n",
    "\toptimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "\t#Train and Test model\n",
    "\tNeuralTrain(trainloader, net, criterion, optimizer, device)\n",
    "\tNeuralTest(testloader, net, criterion, device)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
